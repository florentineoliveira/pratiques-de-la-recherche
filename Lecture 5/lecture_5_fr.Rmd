---
title: "Variables Instrumentales (IV)"
subtitle: "Pratiques de la Recherche en Économie"
author: "Florentine Oliveira-Roux"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ['metropolis', 'metropolis-fonts', 'custom.css']
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r setup, include = FALSE, warning = FALSE, message = FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  dev = "svg",
  cache = TRUE,
  fig.align = "center"
  #fig.width = 11,
  #fig.height = 5
)

# Load packages
library(tidyverse)
library(pander)
library(ggthemes)
library(gapminder)
library(emo)
library(countdown)
library(xaringanthemer)
library(xaringanExtra)
library(sf)

# countdown style
countdown(
  color_border              = "#dd0747",
  color_text                = "black",
  color_running_background  = "#dd0747",
  color_running_text        = "white",
  color_finished_background = "white",
  color_finished_text       = "#dd0747",
  color_finished_border     = "#dd0747",
  font_size = "2em" 
)


style_xaringan( 
  title_slide_background_color = "#dd0747",
  title_slide_text_color = "white",
  text_color = "black",
  header_color = "#dd0747",
  text_bold_color = "#dd0747",
  text_slide_number_color = "black",
  code_inline_background_color = "#e0e1df",
  base_font_size = "24px",
  text_font_family = "Palatino",
  header_font_family = "Palatino",
  header_h1_font_size = "45px",
  header_h2_font_size = "35px",
  header_h3_font_size = "28px",
  inverse_background_color = "#f8cdda",
  inverse_text_color = "black",
  inverse_header_color = "#dd0747")

theme_minimum = theme_bw() + 
  theme(
  text = element_text(family = "Palatino"),
  line = element_blank(),  # Masquer toutes les lignes par défaut
  rect = element_blank(),  # Masquer tous les rectangles par défaut
  axis.line = element_line(color = "black"),  # Afficher les lignes des axes
  axis.ticks = element_blank(),  # Masquer les ticks des axes
  plot.title = element_blank(),  # Masquer le titre du graphique
  panel.background = element_rect(fill = "#FAFAFA", color = "#FAFAFA"), # Masquer le fond du panneau
  panel.grid.major = element_blank(),  # Masquer la grille principale
  panel.grid.minor = element_blank(),  # Masquer la grille secondaire
  plot.background = element_rect(fill = "#FAFAFA", color = "#FAFAFA"), # Masquer le fond du graphique
  legend.position = "none"  # Masquer la légende
)


# A blank theme for ggplot
theme_empty = theme_bw() + 
  theme(
  text = element_text(family = "Palatino"),
  line = element_blank(),  # Masquer toutes les lignes par défaut
  rect = element_blank(),  # Masquer tous les rectangles par défaut
  axis.line = element_line(color = "black"),  # Afficher les lignes des axes
  axis.ticks = element_blank(),  # Masquer les ticks des axes
  axis.text = element_blank(),  # Masquer les étiquettes des axes
  axis.title = element_text(size = 12),  # Afficher les titres des axes
  plot.title = element_blank(),  # Masquer le titre du graphique
  panel.background = element_rect(fill = "#FAFAFA", color = "#FAFAFA"), # Masquer le fond du panneau
  panel.grid.major = element_blank(),  # Masquer la grille principale
  panel.grid.minor = element_blank(),  # Masquer la grille secondaire
  plot.background = element_rect(fill = "#FAFAFA", color = "#FAFAFA"), # Masquer le fond du graphique
  legend.position = "none"  # Masquer la légende
)



#npx decktape \
# --url-load-timeout=60000 --page-load-timeout=60000 --buffer-timeout=60000 \
# --chrome-arg="--disable-web-security" --chrome-arg="--allow-file-access-from-files" \
# "file:///Users/florentineoliveira/Desktop/Teaching/CPES/pratiques-de-la-recherche/Lecture 5/lecture_5_fr.html" \
# "/Users/florentineoliveira/Desktop/Teaching/CPES/pratiques-de-la-recherche/Lecture 5/lecture_5_fr.pdf"

```

layout: true

---
# Selection on unobservables

Les méthodes d'identification basées sur l'**hypothèse d'indépendance conditionnelle** (CIA, ou **selection sur les observables**) supposent qu'en contrôlant par des variables observables $W_i$, l'estimateur OLS donne l'effet causal du traitement $D$
  - i.e. on peut contrôler pour toute la sélection dans le traitement (*mauvaise variation*) par des variables **observées** $W$

&nbsp;

--

```{r ols, echo=FALSE, out.width="40%"}
knitr::include_graphics("imgs/ols.png")
```


---
# Selection on unobservables


.center[`r emo::ji("rotating_light")` <span style="color:#dd0747"> **Il existe (quasiment) TOUJOURS des variables inobservables qui affectent à la fois le traitement et l'outcome**</span> `r emo::ji("rotating_light")`]


--

.center[
<span style="color:#dd0747"> $\color{#dd0747}{\implies}$ **Biais de sélection (le groupe de traitement et contrôle ne sont pas comparables)**</span>
]


--

.center[
<span style="color:#dd0747"> $\color{#dd0747}{\implies} \; D$ **est endogène**</span>
]


--

.center[
<span style="color:#dd0747"> $\implies \; \hat{\beta}$ **n'est pas causal**</span>
]

--

&nbsp;

```{r selection unobs, echo=FALSE, out.width="40%"}
knitr::include_graphics("imgs/selection_unobs.png")
```



---
# Intuition IV

La méthode des **variables instrumentales**

--

- sépare $D$ en une partie exogène (*bonne variation*) et une partie endogène (*mauvaise variation*)
  
--
  
- grâce à une variable que l'on appelle <span style="color:#dd0747">**instrument** $\color{#dd0747}{Z_i}$</span> 
  
--

- pour n'utiliser que la partie exogène dans l'estimation de l'effet du traitement
   
--
   
Cela permet de supprimer le biais de sélection en *supprimant la mauvaise variation* de $D_i$


--

&nbsp;

```{r instrument, echo=FALSE, out.width="50%"}
knitr::include_graphics("imgs/instrument.png")
```



---
# Estimateur IV

On a le modèle usuel:

$$Y_i = \alpha + \beta D_i + W_i + \varepsilon_i$$
&nbsp;


***Rappel***: l'esimateur OLS garantie que l'estimateur de $\beta$ de l'effet du traitement $D$ est causal/bien identifié si et seulement si $Cov(D_i,\varepsilon_i)=0$, ce qui est une <span style="color:#dd0747">hypothèse très forte</span>.

&nbsp;

La méthode des **variables instrumentales** suppose qu'il existe une variable $Z_i$, corrélée avec la variable endogène et qui impacte l'outcome uniquement via son effet sur la variable endogène.


L'<span style="color:#33B8FF">**estimateur IV**</span> s'écrit:

$$\color{#33B8FF}{\hat{\beta}^{IV} = (Z'D)^{-1}(Z'Y)}$$
où $Z=(ZW)$ et $D=(DW)$, avec $W$ les variables de contrôle.


---
# Hypothèses d'identification


<span style="color:#9933FF"> **Relevance:**</span> 
- <span style="color:#9933FF">L'instrument est corrélé à la variable endogène/traitement</span> (cela nous assure qu'on garde bien une partie de la *bonne variation* de  $\color{#9933FF}{D}$ )</span> 
- <span style="color:#9933FF"> Formellement,  $\color{#9933FF}{Cov(D_i, Z_i) \neq 0}$ </span>
- <span style="color:#9933FF"> **Hypothèse testable!**: via la régression de première étape (*first-stage*) en montrant que l'instrument a bien un effet statistiquement significatif sur la variable endogène/instrument + F-stat > 10</span>

&nbsp;

```{r relevance, echo=FALSE, out.width="60%"}
knitr::include_graphics("imgs/relevance.png")
```


---
# Hypothèses d'identification

<span style="color:#9933FF"> **Exclusivité**</span> 
- <span style="color:#9933FF">L'instrument affecte $\color{#9933FF}{Y}$ **uniquement via** $\color{#9933FF}{D}$. Dit autrement, l'instrument n'impacte pas directement $\color{#9933FF}{Y}$ </span> 
- <span style="color:#9933FF"> Hypothèse **NON testable!**</span> 

&nbsp;

```{r exclusion, echo=FALSE, out.width="60%"}
knitr::include_graphics("imgs/exclusion.png")
```



---
# Hypothèses d'identification

<span style="color:#9933FF">**Exogeneité/as-good-as-random:**</span> 
- <span style="color:#9933FF">L'instrument est **exogène** (non corrélé avec le terme d'erreur) </span> 
- <span style="color:#9933FF"> Formellement,  $\color{#9933FF}{Cov(Z_i, \varepsilon_i) = 0}$ </span> 
- <span style="color:#9933FF"> Hypothèse **NON testable!**</span> 

&nbsp;

```{r agar, echo=FALSE, out.width="60%"}
knitr::include_graphics("imgs/exogeneity.png")
```

&nbsp;

*NB: Exogeneité + Exclusivité = Exclusion Restriction*


---
# Comment savoir si un instrument est bon ?


.center[<span style="color:#dd0747">***Les bons instruments doivent paraître bizarre***  `r emo::ji("disbelief")`</span>]


Les bons instruments peuvent sembler **contre-intuitifs**: ils créent un effet sur la variable endogène/instrument mais ne déterminent pas l'outcome.
  - un bon instrument doit susciter la confusion chez un auditeur non averti
  

L’***exclusion restriction***, hypothèse clé mais **non testable**, est plus crédible lorsque l'instrument semble incongru 
  - il faut pouvoir défendre cette hypothèse avec une argumentation logique et théorique

--

Exemples : 
  - composition de genre des deux aînés comme instrument du nombre d'enfants et de l'offre de travail des femmes
  - pluviométrie comme instrument pour le revenu sur la fréquence de conflits
  - loteries


---
# Forme réduite (*Reduced-Form*)

&nbsp;

Le modèle en <span style="color:#33B8FF">**reduced-form**</span>  s'écrit:

$$Y_i = \mu + \color{#eb8934}{\pi} \color{#9e5188}{Z_i} + \nu_i$$

L'estimateur OLS de cette équation donne un estimateur causal de **l'effet de l'instrument** ( $\neq$ effet du traitement $D_i$) sur l'outcome.

L'hypothèse d'identification est que l'instrument est bien exogène ( $Cov(\varepsilon_i, Z_i) = 0$ ) 





---
# Two-stage least squares (2SLS)

--

La méthode des variables instrumentales est souvent utilisée en deux étapes, en l’occurrence lorsqu'il y a plusieurs instruments/variables endogènes:

--

1. <span style="color:#33B8FF">**First stage**</span>: on régresse la variable endogène sur l'instrument et les contrôles, $D_i = \delta + \color{#27b072}{\gamma} Z_i + \xi_i$ et on garde la valeur prédite de la variable endogène $\hat{D}$. La première étape *purge* la variable endogène de sa partie corrélée avec l'erreur et ne conserve que la partie de $D$ qui est corrélée avec l'instrument $Z$.
2. <span style="color:#33B8FF">**Second stage**</span>: on régresse l'outcome sur la valeur prédite de la variable endogène $\hat{D}$ et les variables de contrôle. Cette régression ne conserve donc que la partie de l'instrument $Z$ qui est corrélée avec la variable endogène $D$


L'estimateur 2SLS s'écrit:

$$\color{#33B8FF}{\hat{\beta}^{2SLS} = (D'P_ZD)^{-1}D'P_ZY = \frac{\text{Estimateur de Reduced-Form}}{\text{Estimateur de First Stage}}} = \frac{\color{#eb8934}{\hat{\pi}}}{\color{#27b072}{\hat{\gamma}}} $$

avec $P_Z = Z(Z'Z)^{-1}Z'$ la matrice de projection de $Z$.

--

*NB: lorsque l'on a un seul instrument et une seule variable endogène, l'estimateur IV et 2SLS sont équivalents*

--

.center[`r emo::ji("rotating_light")` Toujours inclure les contrôles dans la *first stage* ET la *second stage* `r emo::ji("rotating_light")`]




---
# Recap: quatres modèles

&nbsp;  


**Modèle avec variable endogène**: 
- $Y_i = \alpha + \beta D_i + W_i + \varepsilon_i$

**First Stage**: régression de la <span style="color:#e07126">**variable endogène**</span> sur l'<span style="color:#9e5188">**instrument**</span> 
- $\color{#e07126}{D_i} = \alpha + \gamma \color{#9e5188}{Z_i} + W_i + \epsilon_i$

**Second Stage**: régression de l'outcome d'intérêt sur les <span style="color:#199c2c">**valeurs prédites en *first stage* **</span> 
- $Y_i = \alpha + \beta \color{#199c2c}{\hat{D_i}} + W_i + \varepsilon_i$

**Reduced Form**: régression de l'outcome sur l'<span style="color:#9e5188">**instrument**</span> 
- $Y_i = \mu + \pi \color{#9e5188}{Z_i} + W_i + \nu_i$




---
# IV sur `R`

## Option 1: à la main

L’estimation peut être réalisée en deux étapes manuelles:

.pull-left[
**Étape 1**:

`first_stage <- lm(D ~ Z + W, data = data)`

`data$D_hat <- predict(first_stage)`           
]

--

.pull-right[
**Étape 2**:

`second_stage <- lm(Y ~ D_hat + W, data = data)`
]

--

&nbsp;  

## Option 2: Package `estimatr`, fonction `iv_robust`

`iv_model <- iv_robust(Y ~ D + W | Z + W, data = data)`

**Avantage**: gère directement l'erreur standard robuste.

.center[`r emo::ji("rotating_light")` Toujours inclure les contrôles dans la first stage et second stage `r emo::ji("rotating_light")`]




---
class: clearinverse
background-color: #f19bb5

&nbsp;

# Application: Angrist and Krueger (1991)


**Question de Recherche**: quel est l'effet du niveau d'études sur le salaire (= *Mincer equation*)?

--

**Question**: pourquoi ne peut-on pas simplement comparer le salaire de deux individus ayant un niveau de diplôme différent?      

--

**Biais de sélection/OVB**: **Ability Bias**
- les individus ayant de meilleures capacités ou davantage de motivation ont tendance à poursuivre leurs études plus longtemps et par ailleurs cela peut également avoir un impact sur leur salaire
- Problème: on n'observe pas la motivation ni les capacités (ie. ces variables sont dans $\varepsilon_i$)
  - donc estimate biaisé 
  
--

<span style="color:#dd0747">**Angrist et Krueger (1991)**</span>
- papier de référence pour la prise en compte du biais d'abilité
- proposent un instrument pour le niveau d'éducation: **le trimestre de naissance** (Quarter of Birth, QOB):

**Contexte**: USA
  - entrée à l'école l'**année des 6 ans**
  - école obligatoire jusqu'à 16 ans
  
  
---
class: clearinverse
background-color: #f19bb5

&nbsp;
 
# Application: Angrist and Krueger (1991)

```{r, echo = T}
library(estimatr)
devtools::install_github("jrnold/masteringmetrics", subdir = "masteringmetrics")
data("ak91", package = "masteringmetrics")

```



---
class: clearinverse
background-color: #f19bb5

&nbsp;

# Application: Angrist and Krueger (1991)


1. Expliquer pourquoi le trimestre de naissance est un bon instrument du nombre d'années d'études? 
  - quel est le mécanisme? l'instrument est-il valide?
  
2. Représenter graphiquement le nombre d'années d'études en fonction du trimestre de naissance. Que constatez-vous?

3. Régressez le salaire sur le nombre d'années d'études. Interprétez.

4. Régressez le nombre d'années d'études sur le trimestre de naissance. Interprétez

5. Régressez le salaire sur le trimestre de naissance. Interprétez.

6. Calculer l'estimateur 2SLS
  - 1) à la main
  - 2) avec la commande `iv_robust`
  
&nbsp;   

[Angrist Data Archive](https://economics.mit.edu/people/faculty/josh-angrist/angrist-data-archive)





---
class: clearinverse
background-color: #fbe6ec

&nbsp;

# Solution : Angrist and Krueger (1991)


1) Expliquer pourquoi le trimestre de naissance est un bon instrument du nombre d'années d'études? 
  - quel est le mécanisme? l'instrument est-il valide?


Mécanisme?

--

  - les enfants nés en début d'année commencent l'école plus tard (6 ans + quelques mois), et ont donc moins d'années d'éducation en moyenne
  - au contraire, les enfants nés en fin d'année commencent l'école plus tôt (5 ans et quelques mois) et passent en moyenne plus de temps scolarisés

--

Instrument valide?

--

  - Relevance: OK
  - Exogeneité: a priori indépendant de l'abilité (peu probable que les élèves les plus habiles choisissent leur date de naissance)
    - Arguments contre: la saisonnalité des naissance peut être corrélée à des facteurs socio-économiques (ex: les profs ont tendance à prévoir leurs enfants pour les vacances scolaires)
  - Excluabilité: n'a pas de raison d'affecter le salaire autrement que par l'effet sur l'éducation



---
class: clearinverse
background-color: #fbe6ec

&nbsp;

# Solution : Angrist and Krueger (1991)

2) Représenter graphiquement le nombre d'années d'études et le salaire en fonction du trimestre de naissance. Que constatez-vous?


```{r, include = T, echo = T,  fig.show = 'hide'}

ak91 %>%
    mutate(qob = as.numeric(as.character(qob)),
           yob = as.numeric(as.character(yob))) %>% 
    filter(yob %in% 1930:1940) %>% 
    group_by(qob, yob) %>%
    summarise(mean_w = mean(lnw), mean_educ = mean(s)) %>%
    mutate(q4 = (qob == 4)) %>% 
    ggplot(aes(x = as.numeric(yob) + ((as.numeric(qob) - 1) / 4), y = mean_educ)) +
    geom_line() +
    geom_label(mapping = aes(label = qob, color = q4), size = 5) +  # Ajout de la taille pour les labels 
    scale_x_continuous("Year of birth", breaks = 1930:1940) +
    scale_y_continuous("Years of Education", breaks = seq(12.2, 13.2, by = 0.1),
                       limits = c(12.2, 13.2)) +
    scale_color_manual(values = c("FALSE" = "grey40", "TRUE" = "#dd0747")) +
    theme_minimum
```

---
count: false
class: clearinverse
background-color: #fbe6ec

&nbsp;

# Solution : Angrist and Krueger (1991)

2) Représenter graphiquement le nombre d'années d'études et le salaire en fonction du trimestre de naissance. Que constatez-vous?


```{r, include = T, echo = F,  dev = "svg", fig.width = 11, fig.height = 6}

ak91 %>%
    mutate(qob = as.numeric(as.character(qob)),
           yob = as.numeric(as.character(yob))) %>% 
    filter(yob %in% 1930:1940) %>% 
    group_by(qob, yob) %>%
    summarise(mean_w = mean(lnw), mean_educ = mean(s)) %>%
    mutate(q4 = (qob == 4)) %>% 
    ggplot(aes(x = as.numeric(yob) + ((as.numeric(qob) - 1) / 4), y = mean_educ)) +
    geom_line() +
    geom_label(mapping = aes(label = qob, color = q4), size = 5) +  # Ajout de la taille pour les labels 
    scale_x_continuous("Year of birth", breaks = 1930:1940) +
    scale_y_continuous("Years of Education", breaks = seq(12.2, 13.2, by = 0.1),
                       limits = c(12.2, 13.2)) +
    scale_color_manual(values = c("FALSE" = "grey40", "TRUE" = "#dd0747")) +
    theme_minimum
```

---
count:false
class: clearinverse
background-color: #fbe6ec

&nbsp;

# Solution : Angrist and Krueger (1991)

2) Représenter graphiquement le nombre d'années d'études et le salaire en fonction du trimestre de naissance. Que constatez-vous?



```{r, include = T, echo = F,  dev = "svg", fig.width = 11, fig.height = 6}

ak91 %>%
    mutate(qob = as.numeric(as.character(qob)),
           yob = as.numeric(as.character(yob))) %>% 
    filter(yob %in% 1930:1940) %>% 
    group_by(qob, yob) %>%
    summarise(mean_w = mean(lnw), 
              mean_educ = mean(s)) %>%
    mutate(q4 = (qob == 4)) %>% 
    ggplot(aes(x = as.numeric(yob) + ((as.numeric(qob) - 1) / 4), y = mean_w)) +
    geom_line() +
    geom_label(mapping = aes(label = qob, color = q4), size = 5) +  
    scale_x_continuous("Year of birth", breaks = 1930:1940) +
    scale_y_continuous("Log weekly wage") +
    scale_color_manual(values = c("FALSE" = "grey40", "TRUE" = "#dd0747")) +
    theme_minimum
```



---
class: clearinverse
background-color: #fbe6ec

&nbsp;

# Solution : Angrist and Krueger (1991)

3) Régressez le salaire sur le nombre d'années d'études. Interprétez

.pull-left[
```{r, echo = T}
ols = lm(lnw ~ s, data = ak91)
summary(ols)
```
]

--

.pull-right[
- Dans un modèle *log-niveau*, $(e^{\hat{\beta}_{OLS}} -1) \times 100 \simeq \hat{\beta} _{OLS} \times 100$ lorsque $\hat{\beta}_{OLS}$ est petit (c'est le cas ici): une année d'études supplémentaire est associée à une augmentation de 7% du salaire hebdomadaire
- Estimate OLS sûrement biaisé
  - Ability corrélée positivement à l'éducation et salaire $\implies$ *downward bias*
]

---
class: clearinverse
background-color: #fbe6ec

&nbsp;

# Solution : Angrist and Krueger (1991)

4) Régressez le nombre d'années d'études sur la dummy Né au Q4. Interprétez

.pull-left[
```{r, echo = T}
fs = lm(s ~ q4, data = ak91 %>% mutate(q4 = (qob == 4)))
summary(fs)
```
]

.pull-right[
- FS statistiquement sognificative! $\implies$ **We have a first stage!!** 
- F-stat = 48 > 10!
]

---
class: clearinverse
background-color: #fbe6ec

&nbsp;

# Solution : Angrist and Krueger (1991)


5) Régressez le salaire sur la dummy Né au Q4. Interprétez.

```{r, echo = T}
rf = lm(lnw ~ q4, data = ak91 %>% mutate(q4 = (qob == 4)))
summary(rf)
```

---
class: clearinverse
background-color: #fbe6ec

&nbsp;

# Solution : Angrist and Krueger (1991)

6) Calculer l'estimateur 2SLS
  - 1) à la main

```{r, echo = T}
# 1) On stocke les prédictions de la FS 
pred_fs = predict(fs)

# 2) On régresse l'outcome sur la prédiction de première étape
ss = lm(ak91$lnw ~ pred_fs)
summary(ss)
```

---
class: clearinverse
background-color: #fbe6ec

&nbsp;

# Solution : Angrist and Krueger (1991)

6) Calculer l'estimateur 2SLS
  - 2) avec la commande `iv_robust`

```{r, echo = T}

ss_b = iv_robust(lnw ~ s | q4, data = ak91 %>% mutate(q4 = (qob == 4)))

summary(ss_b)

```

---
# IV and RCT avec *imperfect compliance*

### Exemple : Women in STEM

On cherche (encore et toujours!) à connaître l'effet des études ( $D_i$ ) sur le salaire ( $Y_i$ )
  - Plus précisément, on s'intéresse à l'effet de poursuivre ses études supérieures dans une filière **STEM**

**Motivation**: les filles sont sous-représentées dans les filières scientifiques alors même qu'elles sont douées en maths
  - Implications à LT sur le salaire 
  - <span style="color:#dd0747">Problème: poursuivre en STEM n'est pas random </span>

**Solution**: Intervention randomisée de <span style="color:#dd0747">**Breda, Grenet, Monnet et Van Effenterre (2023)**</span>
- Interventions en classes (tirées aléatoirement) de femmes scientifiques (*Role Models*) pour déconstruire les stéréotypes de genre dans les sciences et pousser les filles à s’orienter dans les filières scientifiques


---
# IV and RCT avec *imperfect compliance*

--

### Exemple : Women in STEM


$\implies$ **Notre instrument = assignation aléatoire à ce programme**
  - Les filles des classes sélectionnées aléatoirement alors que les filles classes non sélectionnées ne le seront pas
  - Hypothèses: 
    - Exclusivité: n'affecte le salaire que via l'effet sur la probabilité d'aller en CPGE 
    - Exogénéité: par construction de la RCT, les classes sont tirées aléatoirement donc le traitement est exogène
    - Relevance: les filles des classes ayant reçu la visite d'un rôle model sont plus probables de poursuivre en STEM (+3,5 pts ou +30% de s'orienter en CPGE scientifique d'après Breda, Grenet, Monnet et Van Effenterre (2023), aucun effet pour les garçons)

--

Si on estime le modèle en forme réduite, $\text{Salaire}_i = \alpha + \beta \text{Traîté}_i + W_i + \varepsilon_i$, où $D_i = 1$ si l'individu $i$ est assigné au programme, que représente $\beta$?

--

$\beta$ représente la différence de salaire moyen des filles assignées au programme par rapport à celles qui n'ont pas bénéficié de l'intervention; on dit que $\beta$ est l'**Intention To Treat (ITT)**

---
# IV and RCT avec *imperfect compliance*

### Exemple : Women in STEM

**Problème**: imperfect compliance
- toutes les filles assignées à l'intervention ne vont pas poursuivre en STEM (= *never-takers*), donc l'effet est en quelques sortes dilué
- certaines filles y seraient allées même en l'absence de traitement (= *always-takers*)

$\implies$ comparer les assignées aux non-assignées capture l'effet de **l'intervention** sur le salaire, pas l'effet de **s'orienter en STEM**, car toutes les assignées ne s'orientent pas en STEM et d'autres se seraient orientés en STEM même en l'absence d'intervention

--

**Solution**: mesurer l'effet de s'orienter en STEM uniquement pour les filles qui **ont changé d'avis grâce à l'intervention** (=*Compliers*)
  - $\beta$ est alors le Local Average Treatment Effect (LATE), où $LATE = \frac{\text{ITT}}{\text{Proportion de Compliers}}$


---
# IV and RCT avec *imperfect compliance*

### Exemple : Women in STEM

Pour résumer:

**Estimation de l'ITT (Intention-to-Treat)**

On régresse le salaire sur l’assignation pour voir l’effet moyen de l’assignation sur le salaire (*Reduced-Form*):

`itt_model <- lm(salaire ~ Assignation, data = data)`

&nbsp;

**Estimation du LATE (Local Average Treatment Effect)**

On fait une estimation 2SLS:

`iv_model <- iv_robust(salaire ~ STEM | Assignation, data = data)`


---
class: clearinverse
background-color:  #d7e2d8

## Recap: IV

**Les quatre modèles**:
- Modèle endogène: $Y_i = \alpha + \beta D_i + W_i + \varepsilon_i$
- *First Stage*: $D_i = \alpha + \color{#27b072}{\gamma} \color{#9e5188}{Z_i} + W_i + \epsilon_i$
- *Second Stage*: $Y_i = \alpha + \beta \color{#dd0747}{\hat{D}_i} + W_i + \varepsilon_i$
- *Reduced Form*: $Y_i = \mu + \color{#eb8934}{\pi} \color{#9e5188}{Z_i} + W_i + \nu_i$

**Estimateurs**:  $\color{#33B8FF}{\hat{\beta}^{IV} = (Z'D)^{-1}(Z'Y)}$ et $\color{#33B8FF}{\hat{\beta}^{2SLS} = (D'P_ZD)^{-1}D'P_ZY = } \frac{\color{#eb8934}{\hat{\pi}}}{\color{#27b072}{\hat{\gamma}}}$

<span style="color:#9933FF">**Hypothèses d'identification:**</span>
- <span style="color:#9933FF">**Relevance:** $\color{#9933FF}{Cov(D_i, Z_i) \neq 0}$: corrélation entre instrument et variable endogène est non nulle</span>
  - <span style="color:#9933FF">Hypothèse testable! : $\color{#27b072}{\hat{\gamma}}$ significatif + F-stat > 10</span>
- <span style="color:#9933FF">**Exclusivité:** $Z$ affecte $Y$ **uniquement via** $D$; **non testable**</span>
- <span style="color:#9933FF">**Exogénéité:** $\color{#9933FF}{Cov(Z_i, \varepsilon_i) = 0}$; **non testable**</span>


**Implémentation sur `R`**:
- `iv_robust(Y ~ D + W | Z + W, data = data)`; package `estimatr` (SE robustes automatiques)
- À la main: `lm(D ~ Z + W)` puis `lm(Y ~ D_hat + W)`

.center[`r emo::ji("rotating_light")` Toujours inclure les contrôles dans la *first stage* ET la *second stage* `r emo::ji("rotating_light")`]


---
# Sources

[Mastering Metrics R Code](https://jrnold.github.io/masteringmetrics/quarter-of-birth-and-returns-to-schooling.html)    
[Causal inference: The Mixtape, Scott Cunningham](https://mixtape.scunning.com/07-instrumental_variables)    
[Instrumental Variables, Edward Rubin](https://raw.githack.com/edrubin/EC525S19/master/NotesLecture/08IV/08IV.html#1)           
[Instrumental Variables - Applications, Florian Oswald](https://raw.githack.com/edrubin/EC525S19/master/NotesLecture/08IV/08IV.html#1)        






