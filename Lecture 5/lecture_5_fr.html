<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Variables Instrumentales (IV)</title>
    <meta charset="utf-8" />
    <meta name="author" content="Florentine Oliveira" />
    <meta name="date" content="2025-02-20" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Variables Instrumentales (IV)
]
.subtitle[
## Pratiques de la Recherche en √âconomie
]
.author[
### Florentine Oliveira
]
.date[
### 2025-02-20
]

---




layout: true

---
# Selection on unobservables

Les m√©thodes d'identification bas√©es sur l'**hypoth√®se d'ind√©pendance conditionnelle** (CIA, ou **selection sur les observables**) supposent qu'en contr√¥lant par des variables observables `\(W_i\)`, l'estimateur OLS donne l'effet causal du traitement `\(D\)`
  - i.e. on peut contr√¥ler pour toute la s√©lection dans le traitement (*mauvaise variation*) par des variables **observ√©es** `\(W\)`

&amp;nbsp;

--

&lt;img src="imgs/ols.png" width="40%" style="display: block; margin: auto;" /&gt;


---
# Selection on unobservables


.center[üö® &lt;span style="color:#dd0747"&gt; **Il existe (quasiment) TOUJOURS des variables inobservables qui affectent √† la fois le traitement et l'outcome**&lt;/span&gt; üö®]


--

.center[
&lt;span style="color:#dd0747"&gt; `\(\color{#dd0747}{\implies}\)` **Biais de s√©lection (le groupe de traitement et contr√¥le ne sont pas comparables)**&lt;/span&gt;
]


--

.center[
&lt;span style="color:#dd0747"&gt; `\(\color{#dd0747}{\implies} \; D\)` **est endog√®ne**&lt;/span&gt;
]


--

.center[
&lt;span style="color:#dd0747"&gt; `\(\implies \; \hat{\beta}\)` **n'est pas causal**&lt;/span&gt;
]

--

&amp;nbsp;

&lt;img src="imgs/selection_unobs.png" width="40%" style="display: block; margin: auto;" /&gt;



---
# Intuition IV

La m√©thode des **variables instrumentales**

--

- s√©pare `\(D\)` en une partie exog√®ne (*bonne variation*) et une partie endog√®ne (*mauvaise variation*)
  
--
  
- gr√¢ce √† une variable que l'on appelle &lt;span style="color:#dd0747"&gt;**instrument** `\(\color{#dd0747}{Z_i}\)`&lt;/span&gt; 
  
--

- pour n'utiliser que la partie exog√®ne dans l'estimation de l'effet du traitement
   
--
   
Cela permet de supprimer le biais de s√©lection en *supprimant la mauvaise variation* de `\(D_i\)`


--

&amp;nbsp;

&lt;img src="imgs/instrument.png" width="50%" style="display: block; margin: auto;" /&gt;



---
# Estimateur IV

On a le mod√®le usuel:

`$$Y_i = \alpha + \beta D_i + W_i + \varepsilon_i$$`
&amp;nbsp;


***Rappel***: l'esimateur OLS garantie que l'estimateur de `\(\beta\)` de l'effet du traitement `\(D\)` est causal/bien identifi√© si et seulement si `\(Cov(D_i,\varepsilon_i)=0\)`, ce qui est une &lt;span style="color:#dd0747"&gt;hypoth√®se tr√®s forte&lt;/span&gt;.

&amp;nbsp;

La m√©thode des **variables instrumentales** suppose qu'il existe une variable `\(Z_i\)`, corr√©l√©e avec la variable endog√®ne et qui impacte l'outcome uniquement via son effet sur la variable endog√®ne.


L'&lt;span style="color:#33B8FF"&gt;**estimateur IV**&lt;/span&gt; s'√©crit:

`$$\color{#33B8FF}{\hat{\beta}^{IV} = (Z'D)^{-1}(Z'Y)}$$`
o√π `\(Z=(ZW)\)` et `\(D=(DW)\)`, avec `\(W\)` les variables de contr√¥le.


---
# Hypoth√®ses d'identification


&lt;span style="color:#9933FF"&gt; **Relevance:**&lt;/span&gt; 
- &lt;span style="color:#9933FF"&gt;L'instrument est corr√©l√© √† la variable endog√®ne/traitement&lt;/span&gt; (cela nous assure qu'on garde bien une partie de la *bonne variation* de  `\(\color{#9933FF}{D}\)` )&lt;/span&gt; 
- &lt;span style="color:#9933FF"&gt; Formellement,  `\(\color{#9933FF}{Cov(D_i, Z_i) \neq 0}\)` &lt;/span&gt;
- &lt;span style="color:#9933FF"&gt; **Hypoth√®se testable!**: via la r√©gression de premi√®re √©tape (*first-stage*) en montrant que l'instrument a bien un effet statistiquement significatif sur la variable endog√®ne/instrument + F-stat &gt; 10&lt;/span&gt;

&amp;nbsp;

&lt;img src="imgs/relevance.png" width="60%" style="display: block; margin: auto;" /&gt;


---
# Hypoth√®ses d'identification

&lt;span style="color:#9933FF"&gt; **Exclusivit√©**&lt;/span&gt; 
- &lt;span style="color:#9933FF"&gt;L'instrument affecte `\(\color{#9933FF}{Y}\)` **uniquement via** `\(\color{#9933FF}{D}\)`. Dit autrement, l'instrument n'impacte pas directement `\(\color{#9933FF}{Y}\)` &lt;/span&gt; 
- &lt;span style="color:#9933FF"&gt; Hypoth√®se **NON testable!**&lt;/span&gt; 

&amp;nbsp;

&lt;img src="imgs/exclusion.png" width="60%" style="display: block; margin: auto;" /&gt;



---
# Hypoth√®ses d'identification

&lt;span style="color:#9933FF"&gt;**Exogeneit√©/as-good-as-random:**&lt;/span&gt; 
- &lt;span style="color:#9933FF"&gt;L'instrument est **exog√®ne** (non corr√©l√© avec le terme d'erreur) &lt;/span&gt; 
- &lt;span style="color:#9933FF"&gt; Formellement,  `\(\color{#9933FF}{Cov(Z_i, \varepsilon_i) = 0}\)` &lt;/span&gt; 
- &lt;span style="color:#9933FF"&gt; Hypoth√®se **NON testable!**&lt;/span&gt; 

&amp;nbsp;

&lt;img src="imgs/exogeneity.png" width="60%" style="display: block; margin: auto;" /&gt;

&amp;nbsp;

*NB: Exogeneit√© + Exclusivit√© = Exclusion Restriction*


---
# Comment savoir si un instrument est bon ?

&amp;nbsp;

.center[&lt;span style="color:#dd0747"&gt;***Good instruments should feel weird***  ü§®&lt;/span&gt;]

&amp;nbsp;

Les bons instruments peuvent sembler **contre-intuitifs**: ils cr√©ent un effet sur la variable endog√®ne/instrument mais ne d√©terminent pas l'outcome.
  - un bon instrument doit susciter la confusion chez un auditeur non averti
  
&amp;nbsp;

L‚Äô***exclusion restriction***, hypoth√®se cl√© mais **non testable**, est plus cr√©dible lorsque l'instrument semble incongru 
  - il faut pouvoir d√©fendre cette hypoth√®se avec une argumentation logique et th√©orique
&amp;nbsp;  
  
Exemples : 
  - composition de genre des deux premiers enfants comme instrument du numbre d'enfants et l‚Äôoffre de travail des femmes
  - pluviom√©trie comme instrument pour le revenu sur la fr√©quence de conflits
  - lotteries





---
# Two-stage least squares (2SLS)

&amp;nbsp;  

La m√©thode des variables instrumentales est souvent utilis√©e en deux √©tapes, en l'occurence lorsqu'il y a plusieurs instruments/variables endog√®nes:

1. &lt;span style="color:#33B8FF"&gt;**First stage**&lt;/span&gt;: on r√©gresse la variable endog√®ne sur l'instrument et les contr√¥les, `\(D_i = \delta + \color{#27b072}{\gamma} Z_i + \xi_i\)` et on garde la valeur pr√©dite de la variable endog√®ne `\(\hat{D}\)`
2. &lt;span style="color:#33B8FF"&gt;**Second stage**&lt;/span&gt;: on r√©gresse l'outcome sur la valeur pr√©dite de la variable endog√®ne `\(\hat{D}\)` et les variables de contr√¥le. Cette r√©gression ne conserve que la partie de l'instrument `\(Z\)` qui est corr√™l√©e avec la variable endog√®ne `\(D\)`

&amp;nbsp;  

L'estimateur 2SLS s'√©crit:

$$\color{#33B8FF}{\hat{\beta}^{2SLS} = \frac{\text{Estimateur de Reduced-Form}}{\text{Estimateur de First Stage}}} = \frac{\color{#eb8934}{\hat{\pi}}}{\color{#27b072}{\hat{\gamma}}} $$


---
# Forme r√©duite (*Reduced-Form*)

Le mod√®le en &lt;span style="color:#33B8FF"&gt;**reduced-form**&lt;/span&gt;  s'√©crit:

`$$Y_i = \mu + \color{#eb8934}{\pi} \color{#9e5188}{Z_i} + \nu_i$$`

L'estimateur OLS de cette √©quation donne un estimateur causal de **l'effet de l'instrument** ( `\(\neq\)` effet du traitement `\(D_i\)`) sur l'outcome.

L'hypoth√®se d'identification est que l'instrument est bien exog√®ne ( `\(Cov(\varepsilon_i, Z_i) = 0\)` ) 



---
# Recap: quatres mod√®les

&amp;nbsp;  


**Mod√®le avec variable endog√®ne**: 
- `\(Y_i = \alpha + \beta D_i + W_i + \varepsilon_i\)`

**First Stage**: r√©gression de la &lt;span style="color:#e07126"&gt;**variable endog√®ne**&lt;/span&gt; sur l'&lt;span style="color:#9e5188"&gt;**instrument**&lt;/span&gt; 
- `\(\color{#e07126}{D_i} = \alpha + \gamma \color{#9e5188}{Z_i} + W_i + \epsilon_i\)`

**Second Stage**: r√©gression de l'outcome d'int√©r√™t sur les &lt;span style="color:#199c2c"&gt;**valeurs pr√©dites en *first stage* **&lt;/span&gt; 
- `\(Y_i = \alpha + \beta \color{#199c2c}{\hat{D_i}} + W_i + \varepsilon_i\)`

**Reduced Form**: r√©gression de l'outcome sur l'&lt;span style="color:#9e5188"&gt;**instrument**&lt;/span&gt; 
- `\(Y_i = \mu + \pi \color{#9e5188}{Z_i} + W_i + \nu_i\)`




---
# IV sur `R`

## Option 1: √† la main

L‚Äôestimation peut √™tre r√©alis√©e en deux √©tapes manuelles:

.pull-left[
**√âtape 1**:

`first_stage &lt;- lm(D ~ Z + W, data = data)`

`data$D_hat &lt;- predict(first_stage)`           
]

--

.pull-right[
**√âtape 2**:

`second_stage &lt;- lm(Y ~ D_hat + W, data = data)`
]

--

&amp;nbsp;  

## Option 2: Package `estimater`, fonction `iv_robust`

`iv_model &lt;- iv_robust(Y ~ D + W | Z + W, data = data)`

**Avantage**: g√®re directement l'erreur standard robuste.

.center[üö® Toujours inclure les contr√¥les dans la first stage et second stage üö®]




---
background-color: #f19bb5
# Application: Angrist and Krueger (1991)


**Question de Recherche**: quel est l'effet du niveau d'√©tudes sur le salaire (= *Mincer equation*)?

--

**Question**: pourquoi ne peut-on pas simplement comparer le salaire de deux individus ayant un niveau de dipl√¥me diff√©rent?      

--

**Biais de s√©lection/OVB**: **Ability Bias**
- les individus ayant de meilleures capacit√©s ou davantage de motivation ont tendance √† poursuivre leurs √©tudes plus longtemps et par ailleurs cela peut √©galement avoir un impact sur leur salaire
- Probl√®me: on n'observe pas la motivation ni les capacit√©s (ie. ces variables sont dans `\(\varepsilon_i\)`)
  - donc estimate biais√© 
  
--

&lt;span style="color:#dd0747"&gt;**Angrist et Krueger (1991)**&lt;/span&gt;
- papier de r√©f√©rence pour la prise en compte du biais d'abilit√©
- proposent un instrument pour le niveau d'√©ducation: **le trimestre de naissance** (Quarter of Birth, QOB):

**Contexte**: USA
  - entr√©e √† l'√©cole l'**ann√©e des 6 ans**
  - √©cole obligatoire jusqu'√† 16 ans
  
  
---
background-color: #f19bb5
# Application: Angrist and Krueger (1991)


``` r
library(estimatr)
data("ak91", package = "masteringmetrics")
```



---
background-color: #f19bb5
# Application: Angrist and Krueger (1991)


1. Expliquer pourquoi le trimestre de naissance est un bon instrument du nombre d'ann√©es d'√©tudes? 
  - quel est le m√©canisme? l'instrument est-il valide?
  
2. Repr√©senter graphiquement le nombre d'ann√©es d'√©tudes en fonction du trimestre de naissance. Que constatez-vous?

3. R√©gressez le salaire sur le nombre d'ann√©es d'√©tudes. Interpr√©tez.

4. R√©gressez le nombre d'ann√©es d'√©tudes sur le trimestre de naissance. Interpr√©tez

5. R√©gressez le salaire sur le trimestre de naissance. Interpr√©tez.

6. Calculer l'estimateur 2SLS
  - 1) √† la main
  - 2) avec la commande `iv_robust`
  
&amp;nbsp;   

[Angrist Data Archive](https://economics.mit.edu/people/faculty/josh-angrist/angrist-data-archive)





---
background-color: #fbe6ec
# Solution : Angrist and Krueger (1991)


1) Expliquer pourquoi le trimestre de naissance est un bon instrument du nombre d'ann√©es d'√©tudes? 
  - quel est le m√©canisme? l'instrument est-il valide?
  
&amp;nbsp; 

M√©canisme?

--

  - les enfants n√©s en d√©but d'ann√©e commencent l'√©cole plus tard (6 ans + quelques mois), et ont donc moins d'ann√©es d'√©ducation en moyenne
  - au contraire, les enfants n√©s en fin d'ann√©e commencent l'√©cole plus t√¥t (5 ans et quelques mois) et passent en moyenne plus de temps scolaris√©s

--

Instrument valide?

--

  - Relevance: OK
  - Exogeneit√©: ind√©pendant de l'abilit√© (impossible que les √©l√®ves les plus abiles choisissent leur date de naissance)
  - Excluabilit√©: n'a pas de raison d'affecter le salaire autrement que par l'effet sur l'√©ducation



---
background-color: #fbe6ec
# Solution : Angrist and Krueger (1991)

2) Repr√©senter graphiquement le nombre d'ann√©es d'√©tudes et le salaire en fonction du trimestre de naissance. Que constatez-vous?


&lt;img src="lecture_5_fr_files/figure-html/unnamed-chunk-2-1.svg" style="display: block; margin: auto;" /&gt;

---
count:false
background-color: #fbe6ec
# Solution : Angrist and Krueger (1991)

2) Repr√©senter graphiquement le nombre d'ann√©es d'√©tudes et le salaire en fonction du trimestre de naissance. Que constatez-vous?



&lt;img src="lecture_5_fr_files/figure-html/unnamed-chunk-3-1.svg" style="display: block; margin: auto;" /&gt;



---
background-color: #fbe6ec
# Solution : Angrist and Krueger (1991)

3) R√©gressez le salaire sur le nombre d'ann√©es d'√©tudes. Interpr√©tez

.pull-left[

``` r
ols = lm(lnw ~ s, data = ak91)
summary(ols)
```

```
## 
## Call:
## lm(formula = lnw ~ s, data = ak91)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.7540 -0.2367  0.0726  0.3318  4.6357 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 4.9951823  0.0044644  1118.9   &lt;2e-16 ***
## s           0.0708510  0.0003386   209.2   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.6378 on 329507 degrees of freedom
## Multiple R-squared:  0.1173,	Adjusted R-squared:  0.1173 
## F-statistic: 4.378e+04 on 1 and 329507 DF,  p-value: &lt; 2.2e-16
```
]

--

.pull-right[
- Estimate OLS s√ªrement biais√©
- Ability corr√©l√©e positivement √† l'√©ducation et salaire `\(\implies\)` *downward bias*
]

---
background-color: #fbe6ec
# Solution : Angrist and Krueger (1991)

4) R√©gressez le nombre d'ann√©es d'√©tudes sur la dummy N√© au Q4. Interpr√©tez

.pull-left[

``` r
fs = lm(s ~ q4, data = ak91 %&gt;% mutate(q4 = (qob == 4)))
summary(fs)
```

```
## 
## Call:
## lm(formula = s ~ q4, data = ak91 %&gt;% mutate(q4 = (qob == 4)))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.8394  -0.8394  -0.7473   2.2527   7.2527 
## 
## Coefficients:
##             Estimate Std. Error  t value Pr(&gt;|t|)    
## (Intercept) 12.74731    0.00658 1937.396  &lt; 2e-16 ***
## q4TRUE       0.09212    0.01328    6.935 4.07e-12 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.281 on 329507 degrees of freedom
## Multiple R-squared:  0.0001459,	Adjusted R-squared:  0.0001429 
## F-statistic: 48.09 on 1 and 329507 DF,  p-value: 4.069e-12
```
]

.pull-right[
- FS statistiquement sognificative! `\(\implies\)` **We have a first stage!!** 
- F-stat &gt; 10!
]

---
background-color: #fbe6ec
# Solution : Angrist and Krueger (1991)


5) R√©gressez le salaire sur la dummy N√© au Q4. Interpr√©tez.


``` r
rf = lm(lnw ~ q4, data = ak91 %&gt;% mutate(q4 = (qob == 4)))
summary(rf)
```

```
## 
## Call:
## lm(formula = lnw ~ q4, data = ak91 %&gt;% mutate(q4 = (qob == 4)))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.2469 -0.2631  0.0542  0.3580  4.6338 
## 
## Coefficients:
##             Estimate Std. Error  t value Pr(&gt;|t|)    
## (Intercept) 5.898272   0.001361 4332.898   &lt;2e-16 ***
## q4TRUE      0.006813   0.002748    2.479   0.0132 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.6788 on 329507 degrees of freedom
## Multiple R-squared:  1.865e-05,	Adjusted R-squared:  1.562e-05 
## F-statistic: 6.146 on 1 and 329507 DF,  p-value: 0.01317
```

---
background-color: #fbe6ec
# Solution : Angrist and Krueger (1991)

6) Calculer l'estimateur 2SLS
  - 1) √† la main


``` r
# 1) On stocke les pr√©dictions de la FS 
pred_fs = predict(fs)

# 2) On r√©gresse l'outcome sur la pr√©diction de premi√®re √©tape
ss = lm(ak91$lnw ~ pred_fs)
summary(ss)
```

```
## 
## Call:
## lm(formula = ak91$lnw ~ pred_fs)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.2469 -0.2631  0.0542  0.3580  4.6338 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.95549    0.38097  13.008   &lt;2e-16 ***
## pred_fs      0.07396    0.02983   2.479   0.0132 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.6788 on 329507 degrees of freedom
## Multiple R-squared:  1.865e-05,	Adjusted R-squared:  1.562e-05 
## F-statistic: 6.146 on 1 and 329507 DF,  p-value: 0.01317
```

---
background-color: #fbe6ec
# Solution : Angrist and Krueger (1991)

6) Calculer l'estimateur 2SLS
  - 2) avec la commande `iv_robust`


``` r
ss_b = iv_robust(lnw ~ s | q4, data = ak91 %&gt;% mutate(q4 = (qob == 4)))

summary(ss_b)
```

```
## 
## Call:
## iv_robust(formula = lnw ~ s | q4, data = ak91 %&gt;% mutate(q4 = (qob == 
##     4)))
## 
## Standard error type:  HC2 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper     DF
## (Intercept)  4.95549    0.35774   13.85 1.267e-43  4.25434   5.6567 329507
## s            0.07396    0.02801    2.64 8.289e-03  0.01905   0.1289 329507
## 
## Multiple R-squared:  0.1171 ,	Adjusted R-squared:  0.1171 
## F-statistic:  6.97 on 1 and 329507 DF,  p-value: 0.008289
```

---
# IV and RCT avec *imperfect compliance*

## Example 2: Women in STEM

On cherche (encore et toujours!) √† conna√Ætre l'effet des √©tudes ( `\(D_i\)` ) sur le salaire ( `\(Y_i\)` )
  - Plus pr√©cis√©ment, on s'int√©resse √† l'effet d'aller en CPGE **STEM**

Inspir√© de &lt;span style="color:#dd0747"&gt;**Breda, Grenet, Monnet et Van Effenterre (2023)**&lt;/span&gt;

**Motivation**: les filles sont sous-repr√©sent√©es dans les fili√®res scientifiques alors m√™me qu'elles sont dou√©es en maths
  - Implications √† LT sur le salaire 
  - &lt;span style="color:#dd0747"&gt;Probl√®me: aller en CPGE n'est pas random &lt;/span&gt;

**Solution**: Intervention randomis√©e
- interventions en classes tir√©es al√©atoirement de femmes scientifiques (*Role Models*) pour d√©construire les st√©r√©otypes de genre dans les sciences et pousser les filles √† s‚Äôorienter dans les fili√®res scientifiques


---
# IV and RCT avec *imperfect compliance*

## Example 2: Women in STEM


`\(\implies\)` **Notre instrument = assignation al√©atoire √† ce programme**
  - corr√©l√© avec le choix d'aller en CPGE (+3,5 pts ou +30% d'apr√®s Breda, Grenet, Monnet et Van Effenterre (2023))
  - Hypoth√®se: n'affecte le salaire que via l'effet sur la probabilit√© d'aller en CPGE

--

Si on estime le mod√®le en forme r√©duite, `\(\text{Salaire_i} = \alpha + \beta \text{Tra√Æt√©}_i + W_i + \varepsilon_i\)`, o√π `\(D_i = 1\)` si l'individu `\(i\)` est assign√© au programme, que repr√©sente `\(\beta\)`?

--

`\(\beta\)` repr√©sente la diff√©rence de salaire moyen des filles assign√©es au programme par rapport √† celles qui n'ont pas b√©n√©fici√© de l'intervention
  - on dit que `\(\beta\)` est l'**Intention To Treat (ITT)**

---
# IV and RCT avec *imperfect compliance*

## Example 2: Women in STEM

**Probl√®me**: imperfect compliance
- toutes les filles assign√©es √† l'intervention ne vont pas aller en CPGE (= *never-takers*), donc l'effet est en quelques sortes dilu√©
- certaines filles non assign√©es au traitement vont aller en CPGE (= *always-takers*)
`\(\implies\)` l'estimateur ne donne pas vraiment l'effet moyen de la CPGE sur le salaire puisque toutes les personnes trait√©es ne vont pas aller en CPGE

--

**Solution**: mesurer l'effet de la CPGE uniquement pour les filles qui ont chang√© d'avis gr√¢ce √† l'intervention (=*Compliers*)
  - `\(\beta\)` est alors le Local Average Treatment Effect (LATE), o√π `\(LATE = \frac{\text{ITT}}{\text{Proportion de Compliers}}\)`

---
# IV and RCT avec *imperfect compliance*

## Example 2: Women in STEM

Pour r√©sumer:

**Estimation de l'ITT (Intention-to-Treat)**

On r√©gresse le salaire sur l‚Äôassignation pour voir l‚Äôeffet moyen de l‚Äôassignation sur le salaire (*Reduced-Form*):
`itt_model &lt;- lm(salaire ~ Assignation, data = data)`

**Estimation du LATE (Local Average Treatment Effect)**

On fait une estimation 2SLS:

`iv_model &lt;- iv_robust(salaire ~ CPGE | Assignation, data = data)`



---
# Sources

[Mastering Metrics R Code](https://jrnold.github.io/masteringmetrics/quarter-of-birth-and-returns-to-schooling.html)    
[Causal inference: The Mixtape, Scott Cunningham](https://mixtape.scunning.com/07-instrumental_variables)    
[Instrumental Variables, Edward Rubin](https://raw.githack.com/edrubin/EC525S19/master/NotesLecture/08IV/08IV.html#1)           
[Instrumental Variables - Applications, Florian Oswald](https://raw.githack.com/edrubin/EC525S19/master/NotesLecture/08IV/08IV.html#1)        







    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
