---
title: "Régressions Linéaires et Causalité"
subtitle: "Pratiques de la Recherche en Économie"
author: "Florentine Oliveira-Roux"
date: "2 Décembre 2025"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ['metropolis', 'metropolis-fonts', 'custom.css']
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---


```{r setup, include = FALSE, warning = FALSE, message = FALSE}
options(htmltools.dir.version = FALSE)

knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  dev = "svg",
  cache = TRUE,
  fig.align = "center"
  #fig.width = 11,
  #fig.height = 5
)

# Load packages
library(tidyverse)
library(here)
library(pander)
library(ggthemes)
library(gapminder)
library(haven)
library(broom)
library(countdown)
library(xaringanthemer)
library(latex2exp)
library(xaringanExtra)
library(parallel)
library(gridExtra)
#library(xaringancolor)

# countdown style
countdown(
  color_border              = "#dd0747",
  color_text                = "black",
  color_running_background  = "#dd0747",
  color_running_text        = "white",
  color_finished_background = "white",
  color_finished_text       = "#dd0747",
  color_finished_border     = "#dd0747",
  font_size = "1.5em" 
)


style_xaringan( 
  title_slide_background_color = "#dd0747",
  title_slide_text_color = "#eee",
  text_color = "black",
  header_color = "#dd0747",
  text_bold_color = "#dd0747",
  text_slide_number_color = "black",
  code_inline_background_color = "#e0e1df",
  base_font_size = "24px",
  text_font_family = "Palatino",
  header_font_family = "Palatino",
  header_h1_font_size = "45px",
  header_h2_font_size = "35px",
  header_h3_font_size = "28px",
  inverse_background_color = "#f8cdda",
  inverse_text_color = "black",
  inverse_header_color = "#dd0747")

# Theme with only x and y axis ans names
theme_minimum = theme_bw() + 
  theme(
  text = element_text(family = "Palatino"),
  line = element_blank(),  # Masquer toutes les lignes par défaut
  rect = element_blank(),  # Masquer tous les rectangles par défaut
  axis.line = element_line(color = "black"),  # Afficher les lignes des axes
  axis.ticks = element_blank(),  # Masquer les ticks des axes
  plot.title = element_blank(),  # Masquer le titre du graphique
  panel.background = element_rect(fill = "#FAFAFA", color = "#FAFAFA"), # Masquer le fond du panneau
  panel.grid.major = element_blank(),  # Masquer la grille principale
  panel.grid.minor = element_blank(),  # Masquer la grille secondaire
  plot.background = element_rect(fill = "#FAFAFA", color = "#FAFAFA"), # Masquer le fond du graphique
  legend.position = "none"  # Masquer la légende
)


theme_empty = theme_bw() + 
  theme(
  text = element_text(family = "Palatino"),
  line = element_blank(),  # Masquer toutes les lignes par défaut
  rect = element_blank(),  # Masquer tous les rectangles par défaut
  axis.line = element_line(color = "black"),  # Afficher les lignes des axes
  axis.ticks = element_blank(),  # Masquer les ticks des axes
  axis.text = element_blank(),  # Masquer les étiquettes des axes
  axis.title = element_text(size = 12),  # Afficher les titres des axes
  plot.title = element_blank(),  # Masquer le titre du graphique
  panel.background = element_rect(fill = "#FAFAFA", color = "#FAFAFA"),  # Masquer le fond du panneau
  panel.grid.major = element_blank(),  # Masquer la grille principale
  panel.grid.minor = element_blank(),  # Masquer la grille secondaire
  plot.background = element_rect(fill = "#FAFAFA", color = "#FAFAFA"),  # Masquer le fond du graphique
  legend.position = "none"  # Masquer la légende
)



#npx decktape \
# --url-load-timeout=60000 --page-load-timeout=60000 --buffer-timeout=60000 \
# --chrome-arg="--disable-web-security" --chrome-arg="--allow-file-access-from-files" \
# "file:///Users/florentineoliveira/Desktop/Teaching/CPES/pratiques-de-la-recherche/Lecture 3/lecture_3_fr.html" \
# "/Users/florentineoliveira/Desktop/Teaching/CPES/pratiques-de-la-recherche/Lecture 3/lecture_3_fr.pdf"

```


```{r dataset simulation, include = F, cache = T}
set.seed(123)

# Population and sample size
n_population = 100
n_sample = 40

# True parameters
a = 1.6
b = 0.7

# Regressor and error term
x = rnorm(n_population, mean = 3, sd = 1.5)
e = rnorm(n_population, mean = 0, sd = 1)
  
# Outcome
y = a + b*x + e

# Dataframe
df_simulation = data.frame(
  a = rep(a, n_population),
  b = rep(b, n_population),
  x = x,
  e = e,
  y = y,
  s1 = sample(x = c(rep(TRUE, n_sample), rep(FALSE, n_population - n_sample))),
  s2 = sample(x = c(rep(TRUE, n_sample), rep(FALSE, n_population - n_sample))),
  s3 = sample(x = c(rep(TRUE, n_sample), rep(FALSE, n_population - n_sample)))
)

# Regressions
lm0 <- lm(y ~ x, data = df_simulation)
lm1 <- lm(y ~ x, data = filter(df_simulation, s1 == T))
lm2 <- lm(y ~ x, data = filter(df_simulation, s2 == T))
lm3 <- lm(y ~ x, data = filter(df_simulation, s3 == T))

```

layout: true

---
# Cette séance


1. Rappels : Régression linéaire simple   
  1.1. Interprétation géométrique      
  1.2. Formule de l'estimateur MCO dans le cas univarié   
  1.3. Hypothèses et propriétés     
  1.4. Implémentation sur `R`     
  1.5. Application: performances scolaires et taille de la fratie

2. Causalité  
  2.1.  Corrélation *vs* Causalité   
  2.2.  Potential Outcomes Framework   
  2.3.  Application: simulations

3. Randomized Controlled Trials (RCT)      
  3.1.  Résolution du problème de sélection         
  3.2.  Application : STAR Experiment         
  3.2.  Limites (coût, ethique, durée, etc)            
  


---
count: false
layout: false
class: center, middle, inverse

# <span style="color:#FAFAFA;">1. Rappels: Régression linéaire simple</span>



---
count:false
class: middle, center,  clearinverse
background-color:  #f8cdda

# <span style="color:#dd0747;">1.1. Interprétation géométrique</span>


---
# Relation linéaire  

La régression linéaire simple est une méthode statistique permettant de trouver une relation **linéaire** entre

  * une **variable expliquée** (ou **variable dépendante** ou ***outcome***), *** $y$ ***
  
  * une **variable explicative** (ou **variable indépendante** ou **régresseur**), *** $x$ ***
  
  
La relation linéaire entre $y$ et $x$ n'est pas parfaite: elle est perturbée par une **erreur** (ou **bruit** ou ***noise***), $\varepsilon$ qui comprend tous les facteurs **non observés** qui affectent $y$.


Le modèle linéaire univarié s'écrit, $\forall \; i$, 

$$y_i = \beta_0 + \beta_1x_i + \varepsilon_i$$


---
# Visualisation   

On considère l'échantillon suivant

--

```{R, nuage, echo = F, dev = "svg", fig.width = 12, fig.height = 6}
ggplot(data = df_simulation, aes(x = x, y = y)) +
  geom_point(size = 3, color = "black", alpha = 0.9) +
  scale_x_continuous(limits = c(-1,8)) +
  scale_y_continuous(limits = c(0.5,7)) +
  theme_empty 

```

---
count: false
# Visualisation    

Pour toute droite $\tilde{y} = \tilde{\beta_0} + \tilde{\beta_1} x$,

```{R, nuage et droite, echo = F, dev = "svg",  fig.width = 12, fig.height = 6}
# Define a function
y_hat <- function(x, b0, b1) {b0 + b1 * x}
# Define line's parameters
b0 <- 4
b1 <- 0.4
# The plot
x_min2 <- sort(df_simulation$x)[2]
y_min2 <- df_simulation$y[df_simulation$x == x_min2]
y_hat_min2 <- y_hat(x_min2, b0, b1)

ggplot(data = df_simulation, aes(x = x, y = y)) +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#f08b27", size = 1, alpha = 0.9)  +
    annotate("text", x = -0.4, y = 3.2, label = "tilde(y)", parse = TRUE, color = "#f08b27", size = 6, family = "serif") +
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty

```




---
count: false
# Visualisation    

Pour toute droite $\tilde{y} = \tilde{\beta_0} + \tilde{\beta_1} x$, on peut calculer les erreurs: $\varepsilon_i = y_i - \tilde{y}_i$

```{R, nuage et droite et point y2, echo = F, dev = "svg",  fig.width = 12, fig.height = 6}

ggplot(data = df_simulation, aes(x = x, y = y)) +
  geom_point(size = 3, color = "black", alpha = 0.9) +
  geom_point(data = df_simulation %>% filter(x == x_min2), size = 3, color = "#f08b27", alpha = 0.9) +
  geom_abline(intercept = b0, slope = b1, color = "#f08b27", size = 1, alpha = 0.9) + 
  annotate("text", x = x_min2, y = y_min2 - 0.2, label = paste0("y[2]"), parse = TRUE, color = "#f08b27", size = 6, family = "serif") +
  annotate("text", x = -0.4, y = 3.2, label = "tilde(y)", parse = TRUE, color = "#f08b27", size = 6, family = "serif") +
  scale_x_continuous(limits = c(-1,8)) +
  scale_y_continuous(limits = c(0.5,7)) +
  theme_empty

```


---
count: false
# Visualisation    

Pour toute droite $\tilde{y} = \tilde{\beta_0} + \tilde{\beta_1} x$, on peut calculer les erreurs: $\varepsilon_i = y_i - \tilde{y}_i$

```{R, nuage et droite et point y2 et e2, echo = F, dev = "svg",   fig.width = 12, fig.height = 6}

ggplot(data = df_simulation, aes(x = x, y = y)) +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    geom_point(data = df_simulation %>% filter(x == x_min2), size = 3, color = "#f08b27", alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#f08b27", size = 1, alpha = 0.9) +
    geom_segment(aes(x = x_min2, xend = x_min2, y = y_min2, yend = y_hat_min2), color = "#f08b27", size = 0.5, alpha = 0.2) +
    annotate("text", x = -0.4, y = 3.2, label = "tilde(y)", parse = TRUE, color = "#f08b27", size = 6, family = "Palatino") +
    annotate("text", x = x_min2, y = y_min2 - 0.2, label = "y[2]", parse = TRUE, color = "#f08b27", size = 6, family = "Palatino") +
    annotate("text", x = x_min2 - 0.1, y = (y_min2 + y_hat_min2) / 2, label = "epsilon[2]", parse = TRUE, color = "#f08b27", size = 6, family = "Palatino") +
    #annotate("text", x = x_min2, y = y_min2 - 0.2, label = paste0("y[2]"), parse = TRUE, color = "#f08b27", size = 6, family = "Palatino") +
    #annotate("text", x = x_min2 - 0.1, y = (y_min2 + y_hat_min2) / 2, label = expression(epsilon[2]), color = "#f08b27", size = 6, family = "Palatino") +
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty
```


---
count: false
# Visualisation    

Pour toute droite $\tilde{y} = \tilde{\beta_0} + \tilde{\beta_1} x$, on peut calculer les erreurs: $\varepsilon_i = y_i - \tilde{y}_i$

```{R, nuage et droite et toutes erreurs, echo = F, dev = "svg", fig.width = 12, fig.height = 6}

ggplot(data = df_simulation, aes(x = x, y = y)) +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#f08b27", size = 1, alpha = 0.9) +
    geom_segment(aes(x = x, xend = x, y = y, yend = y_hat(x, b0, b1)), size = 0.5, alpha = 0.2) +
    annotate("text", x = -0.4, y = 3.2, label = "tilde(y)", parse = TRUE, color = "#f08b27", size = 6, family = "serif") +
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty
```


---
count: false
# Visualisation  

Pour toute droite $\tilde{y} = \tilde{\beta_0} + \tilde{\beta_1} x$, on peut calculer les erreurs: $\varepsilon_i = y_i - \tilde{y}_i$

```{R, nuage et autre droite et toutes erreurs , echo = F, dev = "svg",  fig.width = 12, fig.height = 6}
b0 <- 5
b1 <- -0.2

ggplot(data = df_simulation, aes(x = x, y = y)) +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#f08b27", size = 1, alpha = 0.9) +
    geom_segment(aes(x = x, xend = x, y = y, yend = y_hat(x, b0, b1)), size = 0.5, alpha = 0.2) +
    annotate("text", x = -0.4, y = 5.6, label = "tilde(y)", parse = TRUE, color = "#f08b27", size = 6, family = "Palatino") +
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty
```



---
count: false
# Visualisation     

SCE = $\left(\sum \varepsilon_i^2\right)$: les erreurs importantes sont davantage pénalisées

```{R, penalties, echo = F, dev = "svg",  fig.width = 12, fig.height = 6}

df_simulation = df_simulation %>%
  mutate(y_hat = y_hat(x, b0, b1),
         distance = abs(y - y_hat))

ggplot(data = df_simulation, aes(x = x, y = y)) +
    annotate("text", x = -0.4, y = 5.6, label = "tilde(y)", parse = TRUE, color = "#f08b27", size = 6, family = "Palatino") +
    geom_rect(aes(xmin = x, xmax = x + distance, ymin = pmin(y, y_hat), ymax = pmax(y, y_hat)), 
              color = "#f7c593", fill = "#f7c593", alpha = 0.09) +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#f08b27", size = 1, alpha = 0.9) +
    geom_segment(aes(x = x, xend = x, y = y, yend = y_hat(x, b0, b1)), size = 0.5, alpha = 0.2) +
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty
```


---
count: false
# Visualisation     

L'estimateur des MCO (*OLS*) calcule $\hat{\beta_0}$ et $\hat{\beta_1}$ qui **<span style="color:#dd0747;">minimisent la SCE</span>**.

```{R, mco penalties, echo = F, dev = "svg",  fig.width = 12, fig.height = 6}
# Define a function
y_hat <- function(x, b0, b1) {b0 + b1 * x}
# Define line's parameters
b0 <- lm0$coefficients[1]
b1 <- lm0$coefficients[2]

# The plot
df_simulation = df_simulation %>%
  mutate(y_hat = y_hat(x, b0, b1),
         distance = abs(y - y_hat))

ggplot(data = df_simulation, aes(x = x, y = y)) +
    annotate("text", x = -0.4, y = 2, label = "hat(y)", parse = TRUE, color = "#dd0747", size = 6, family = "Palatino") +
    geom_rect(aes(xmin = x, xmax = x + distance, ymin = pmin(y, y_hat), ymax = pmax(y, y_hat)), 
              color = "#f7c593", fill = "#f7c593", alpha = 0.09) +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#dd0747", size = 1, alpha = 0.9) +
    geom_segment(aes(x = x, xend = x, y = y, yend = y_hat(x, b0, b1)), size = 0.5, alpha = 0.2) +   
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty 
```

---
count: false
# Visualisation     

L'estimateur des MCO (*OLS*) calcule $\hat{\beta_0}$ et $\hat{\beta_1}$ qui **<span style="color:#dd0747;">minimisent la SCE</span>**.

```{R, mco, echo = F, dev = "svg",  fig.width = 12, fig.height = 6}

ggplot(data = df_simulation, aes(x = x, y = y)) +
    annotate("text", x = -0.4, y = 2, label = "hat(y)", parse = TRUE, color = "#dd0747", size = 6, family = "Palatino") +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#dd0747", size = 1, alpha = 0.9) +
    geom_segment(aes(x = x, xend = x, y = y, yend = y_hat(x, b0, b1)), size = 0.5, alpha = 0.2) +
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty 
```


---
count:false
class: middle, center,  clearinverse
background-color:  #f8cdda

# <span style="color:#dd0747;">1.2. Formule de l'estimateur MCO dans le cas univarié</span>


---
name: OLS
# Estimateur MCO dans le cas univarié  

L'estimateur des MCO calcule $\hat{\beta_0}$ et $\hat{\beta_1}$ qui minimmise la Somme des Carrés des Erreurs (SCE, ou *Sum of Squared Errors*) : 

$$\min_{\hat{\beta_0},\, \hat{\beta_1}} \text{SCE} =\sum_{i=1}^N \varepsilon _i^2$$
On obtient, dans le cas univarié:

.center[
$\hat{\beta_0} = \overline{y} - \hat{\beta_1} \overline{x}$ 

$\hat{\beta_1} = \dfrac{Cov(x,y)}{Var(x)}$
]

[Maths modèle univarié](#derivation)


---
count:false
class: middle, center,  clearinverse
background-color:  #f8cdda

# <span style="color:#dd0747;">1.3. Hypothèses</span>



---
name:hypothesis
# Hypothèses

<span style="color:#9933FF"> $\color{#9933FF}{H_1}$ **Linéarité**</span>: le modèle est linéaire dans les paramètres
  - Formellement, $\color{#9933FF}{\frac{\partial y_i}{\partial x_{ik}} = \beta_k}$,  $\color{#9933FF}{\forall k =1, ..., K}$
  

<span style="color:#9933FF"> $\color{#9933FF}{H_2}$ **Échantillon Aléatoire**</span>: l'échantillon $(x_i, y_i)$ est un échantillon aléatoire et représentatif de la population.
  - [Visualisation](#randomsample)

  
<span style="color:#9933FF"> $\color{#9933FF}{H_3}$ **Exogeneité/Identification**</span>: $X$ est exogène
  - Formellement, $\color{#9933FF}{\mathbb{E}(\varepsilon_i|x) = 0}$   


<span style="color:#9933FF"> $\color{#9933FF}{H_4}$ **Variation**:</span> il y a suffisamment de variation dans $x$. 
  - Dit autrement, chaque variable explicative apporte une information qui lui est propre
  - Formellement, les explicatives ne sont pas colinéaires (cas univarié: $\color{#9933FF}{x_i \neq}$ <span style="color:#9933FF">constante</span>)
  - `r emo::ji("rotating_light")` [Outliers](#outliers)
  


---
name: hypothesis2
# Hypothèses

  
<span style="color:#9933FF"> $\color{#9933FF}{H_5}$ **Les erreurs $\varepsilon_i$ sont sphériques** </span>:
  - <span style="color:#9933FF"> $\color{#9933FF}{H_{5a}}$ **Homoscédasticité** </span>: la variance est constante : $\color{#9933FF}{\forall i}$, $\color{#9933FF}{\mathbb{V}(\varepsilon_i|x) = \mathbb{E}(\varepsilon_i^2|x) = \sigma^2}$    
    - [Visualisation](#heteroscedasticity)
  - <span style="color:#9933FF"> $\color{#9933FF}{H_{5b}}$ **Absence d'autocorrélation** </span>: $\color{#9933FF}{\mathbb{E}(\varepsilon_i\varepsilon_j|x) =  0, \forall i \neq j}$
  
  &nbsp;

<span style="color:#9933FF"> **Propriété: Normalité (asymptotique)**:</span> sous hypothèse que l'échantillon $(x_{i}, y_{i})$ est $iid$, l'esitmateur $\hat{\beta}$ suit une loi normale:  $$\color{#9933FF}{\hat{\beta} \; {\sim} \; \mathcal{N}(\beta, \mathbb{V}(\hat{\beta})) }$$

&nbsp;

<span style="color:#dd0747">**Sous ces hypothèses, l'estimateur des MCO est BLUE (Best Linear Unbiased Estimator)**</span> (cf démonstrations faites en cours).


---
count:false
class: middle, center,  clearinverse
background-color:  #f8cdda

# <span style="color:#dd0747;">1.4. Implémentation sur `R`</span>


---
# Commandes/fonctions `R`

- Calcul de la variance empirique

```{r, echo = TRUE, eval = FALSE}
var(x)
```

- Calcul de la covariance empirique
```{r, echo = TRUE, eval = FALSE}
cov(x,y)
```

- Régression linéaire (simple)
```{r, echo = TRUE, eval = FALSE}
lm(variable dépendante ~  variable indépendante, data = data.frame)
```

- Résultats de l'estimation visibles avec la commande `summary`




---
class: clearinverse
background-color:  #f19bb5

&nbsp;

# Application

### Performances scolaires et salaire

`r countdown(minutes = 5, top = 0)`

**Cleaning** 


1) Importer la base de données `eec_t1_2017_simulated_wage.rds` que vous nommerez `df`

2) Effectuer les opérations ne nettoyage de données suivantes:
  - ne conserver que les enfants âgés d'au moins 30 ans (*hint: utiliser la variable `AGE5`*)
  - créer la variable `log_wage`, le log du salaire net mensuel winsorisé
  - créer la variable `educ`, à partir de `DIP11` en la recodant de 1 (pas de diplôme) à 10 (doctorat), en regroupant les diplômes de niveau équivalent (*hint: utiliser le DM de l'année dernière pour vérifier l'intitulé du niveau de diplôme*)


**Intuition** 

3) Selon vous, quelle est la relation entre **salaire** et **performances scolaires** ?


---
class: clearinverse
background-color:  #f19bb5

&nbsp;

# Application

### Performances scolaires et salaire

`r countdown(minutes = 5, top = 0)`


**Sur `R`: se familiariser avec les données**

4) Représenter le nuage de points qui définit la relation entre le **salaire** (log winsorisé) et **le niveau de diplôme** en ne gardant uniquement le valeurs de `log_wage` positives et les valeurs d'`educ` non manquantes

5) Calculer les estimateurs de $\beta_0$ et $\beta_1$ du modèle $\text{Wage} = \beta_0 + \beta_1 \text{Educ} + \varepsilon$, à la main et directement via la fonction `lm` en ne gardant uniquement le valeurs de `log_wage positives` et les valeurs d'`educ` non manquantes


---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution

### Cleaning

1) Importer la base de données `eec_t1_2017_simulated_wage.rds` que vous nommerez `df`


```{r, echo=T, eval = T}
# Import data
df = readRDS("data/eec_t1_2017_simulated_wage.rds")
```

---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution


2) Effectuer les opérations ne nettoyage de données suivantes:
  - ne conserver que les enfants âgés d'au moins 30 ans (*hint: utiliser la variable `AGE5`*)
  - créer la variable `log_wage`, le log du salaire net mensuel winsorisé
  - créer la variable `educ`, à partir de `DIP11` en la recodant de 1 (pas de diplôme) à 10 (doctorat), en regroupant les diplômes de niveau équivalent (*hint: utiliser le DM de l'année dernière pour vérifier l'intitulé du niveau de diplôme*)


```{r, echo=T, eval = T}
df = df %>% 
  filter(AGE5 != 15) %>%  
  mutate(log_wage = log(ifelse(wage>quantile(wage, seq(0,1,0.01), na.rm = T)[100] ,quantile(wage, seq(0,1,0.01), na.rm = T)[100], wage)),
    educ = case_when(
      DIP11 == "71" ~ 1,  # Sans diplôme
      DIP11 == "70" ~ 2,  # Certificat d'Études Primaires (CEP)
      DIP11 == "60" ~ 3,  # Brevet des collèges
      DIP11 == "50" ~ 4,  # CAP, BEP ou équivalents
      DIP11 %in% c("41", "42") ~ 5,  # Baccalauréat (Général, technologique, professionnel)
      DIP11 %in% c("30", "31", "33") ~ 6,  # Niveau Bac+2 (DEUG, BTS, DUT, paramédical/social)
      DIP11 == "11" ~ 7,  # Écoles de niveau licence et au-delà
      DIP11 == "10" ~ 8,  # Licence (L3) et Maîtrise (M1)
      DIP11 == "10" ~ 9,  # Master, DEA, DESS
      DIP11 == "10" ~ 10, # Doctorat
      TRUE ~ NA_real_  # Valeurs manquantes
  ))

```
 
 
 


  
---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution


2) Effectuer les opérations ne nettoyage de données suivantes:
  - **ne conserver que les enfants âgés d'au moins 30 ans (*hint: utiliser la variable `AGE5`*)**
  - créer la variable `log_wage`, le log du salaire net mensuel winsorisé
  - créer la variable `educ`, à partir de `DIP11` en la recodant de 1 (pas de diplôme) à 10 (doctorat), en regroupant les diplômes de niveau équivalent (*hint: utiliser le DM de l'année dernière pour vérifier l'intitulé du niveau de diplôme*)


```{r, echo=T, eval = T}
df = df %>% 
  filter(AGE5 != 15) %>%  #<<
  mutate(log_wage = log(ifelse(wage>quantile(wage, seq(0,1,0.01), na.rm = T)[100], quantile(wage, seq(0,1,0.01), na.rm = T)[100] ,wage)),     
    educ = case_when(
      DIP11 == "71" ~ 1,  # Sans diplôme
      DIP11 == "70" ~ 2,  # Certificat d'Études Primaires (CEP)
      DIP11 == "60" ~ 3,  # Brevet des collèges
      DIP11 == "50" ~ 4,  # CAP, BEP ou équivalents
      DIP11 %in% c("41", "42") ~ 5,  # Baccalauréat (Général, technologique, professionnel)
      DIP11 %in% c("30", "31", "33") ~ 6,  # Niveau Bac+2 (DEUG, BTS, DUT, paramédical/social)
      DIP11 == "11" ~ 7,  # Écoles de niveau licence et au-delà
      DIP11 == "10" ~ 8,  # Licence (L3) et Maîtrise (M1)
      DIP11 == "10" ~ 9,  # Master, DEA, DESS
      DIP11 == "10" ~ 10, # Doctorat
      TRUE ~ NA_real_  # Valeurs manquantes
  ))

```
 

---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution


2) Effectuer les opérations ne nettoyage de données suivantes:
  - ne conserver que les enfants âgés d'au moins 30 ans (*hint: utiliser la variable `AGE5`*)
  - **créer la variable `log_wage`, le log du salaire net mensuel winsorisé**
  - créer la variable `educ`, à partir de `DIP11` en la recodant de 1 (pas de diplôme) à 10 (doctorat), en regroupant les diplômes de niveau équivalent (*hint: utiliser le DM de l'année dernière pour vérifier l'intitulé du niveau de diplôme*)


```{r, echo=T, eval = T}
df = df %>% 
  filter(AGE5 != 15) %>%  
  mutate(log_wage = log(ifelse(wage>quantile(wage, seq(0,1,0.01), na.rm = T)[100] ,quantile(wage, seq(0,1,0.01), na.rm = T)[100] ,wage)), #<<
    educ = case_when(
      DIP11 == "71" ~ 1,  # Sans diplôme
      DIP11 == "70" ~ 2,  # Certificat d'Études Primaires (CEP)
      DIP11 == "60" ~ 3,  # Brevet des collèges
      DIP11 == "50" ~ 4,  # CAP, BEP ou équivalents
      DIP11 %in% c("41", "42") ~ 5,  # Baccalauréat (Général, technologique, professionnel)
      DIP11 %in% c("30", "31", "33") ~ 6,  # Niveau Bac+2 (DEUG, BTS, DUT, paramédical/social)
      DIP11 == "11" ~ 7,  # Écoles de niveau licence et au-delà
      DIP11 == "10" ~ 8,  # Licence (L3) et Maîtrise (M1)
      DIP11 == "10" ~ 9,  # Master, DEA, DESS
      DIP11 == "10" ~ 10, # Doctorat
      TRUE ~ NA_real_  # Valeurs manquantes
  ))

```
 
---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution

2) Effectuer les opérations ne nettoyage de données suivantes:
  - ne conserver que les enfants âgés d'au moins 30 ans (*hint: utiliser la variable `AGE5`*)
  - créer la variable `log_wage`, le log du salaire net mensuel winsorisé   
  - **créer la variable `educ`, à partir de `DIP11` en la recodant de 1 (pas de diplôme) à 10 (doctorat), en regroupant les diplômes de niveau équivalent (*hint: utiliser le DM de l'année dernière pour vérifier l'intitulé du niveau de diplôme*)**

```{r, echo=T, eval = T}
df = df %>% 
  filter(AGE5 != 15) %>%  
  mutate(log_wage = log(ifelse(wage>quantile(wage, seq(0,1,0.01), na.rm = T)[100] ,quantile(wage, seq(0,1,0.01), na.rm = T)[100] ,wage)),,
    educ = case_when(
      DIP11 == "71" ~ 1,  # Sans diplôme #<<
      DIP11 == "70" ~ 2,  # Certificat d'Études Primaires (CEP)  #<<
      DIP11 == "60" ~ 3,  # Brevet des collèges #<<
      DIP11 == "50" ~ 4,  # CAP, BEP ou équivalents #<<
      DIP11 %in% c("41", "42") ~ 5,  # Baccalauréat (Général, technologique, professionnel) #<<
      DIP11 %in% c("30", "31", "33") ~ 6,  # Niveau Bac+2 (DEUG, BTS, DUT, paramédical/social) #<<
      DIP11 == "11" ~ 7,  # Écoles de niveau licence et au-delà #<<
      DIP11 == "10" ~ 8,  # Licence (L3) et Maîtrise (M1) #<<
      DIP11 == "10" ~ 9,  # Master, DEA, DESS #<<
      DIP11 == "10" ~ 10, # Doctorat #<<
      TRUE ~ NA_real_  # Valeurs manquantes #<<
  ))

```
 



---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution

### Intuition 

3) Selon vous, quelle est la relation entre **salaire** et **performances scolaires** ?

--

- Selon la théorie du capital humain, on s'attend à une relation positive entre le niveau de diplôme et le salaire

--

- Cette relation peut-être non-linéaire avec des rendements marginaux décroissants 
  - l'écart de salaire entre le doctorat et le master pourrait être plus faible qu'entre le baccalauréat et le CAP)
  
--
  
- Voire des rendements hétérogènes selon les filières (un master professionnel en finance versus un master recherche en lettres)

--

$\implies$ Soulève la question de savoir si le diplôme mesure réellement la productivité ou s'il sert plutôt de signal sur le marché du travail, comme le suggère la théorie du signalement de Spence



---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution 

4) Représenter le nuage de points qui définit la relation entre le **salaire** (log winsorisé) et **le niveau de diplôme** en ne gardant uniquement le valeurs de `log_wage` positives et les valeurs d'`educ` non manquantes

--


```{r, echo=FALSE,fig.width = 10, fig.height = 6}
g_wage_educ = ggplot(df %>% filter(!is.na(educ)), aes(x = as.factor(educ), y = as.numeric(log_wage))) + 
  geom_point(size = 2, alpha = 0.5) +
  #xlim(0, 10) +
  labs(
    x = "Niveau de diplôme",
    y = "Salaire mensuel net (log)",
    title = "") +
  theme_minimum

g_wage_educ
```



```{r, echo = F, eval = F}
# g_educ = ggplot(data, aes(x = education, y = as.numeric(log_weekly_wage))) + 
#   geom_point(size = 2, alpha = 0.5) +
#   xlim(0,20) +
#   ylim(-3, 15) +
#   labs(
#     x = "Highest grade completed",
#     y = "Log(weekly wage)",
#     title = "") +
#   theme_bw(base_size = 20)
# g_educ


```


```{r, echo=FALSE, include = F, fig.width = 8, fig.height = 5}

wage_avg_educ = df %>%
 filter(log_wage > 0, !is.na(educ)) %>% 
 group_by(educ) %>%
 summarise(mean_wage = mean(log_wage, na.rm = TRUE))

g_wage_educ_avg = ggplot(wage_avg_educ, aes(x = educ, y = mean_wage)) + 
   geom_point(size = 3) +
   geom_line() +
   #xlim(0, 10) +
   ylim(6.8,8.3) + 
   labs(
     x = "Niveau de diplôme",
     y = "Salaire moyen (log)",
     title = "") +
   theme_minimum
g_wage_educ_avg


# wage_avg_grade <- data %>%
#  group_by(education) %>%
#  summarise(mean_wage = mean(log_weekly_wage))
# 
# g_wage_educ = ggplot(wage_avg_grade, aes(x = education, y = mean_wage)) + 
#    geom_point(size = 2) +
#    xlim(0,8) +
#    ylim(0, 20) +
#    labs(
#     x = "Highest grade completed",
#     y = "Log(weekly wage)",
#      title = "") +
#    theme_bw(base_size = 20)
# g_wage_educ


```

---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution 

5) Calculer les estimateurs de $\beta_0$ et $\beta_1$ du modèle $\text{Wage} = \beta_0 + \beta_1 \text{Educ} + \varepsilon$, à la main et directement via la fonction `lm` en ne gardant uniquement le valeurs de `log_wage` positives et les valeurs d'`educ` non manquantes

```{r, echo=T, eval = T}

df_clean = df %>% filter(log_wage > 0, !is.na(educ))

# 1: Calcul à la main
beta_1 = cov(df_clean$educ, df_clean$log_wage) / var(df_clean$educ, na.rm = TRUE)
beta_1
beta_0 = mean(df_clean$log_wage, na.rm = TRUE) - beta_1 * mean(df_clean$educ, na.rm = TRUE)
beta_0

# 2: Via lm
summary(lm(log_wage ~ educ, data = df_clean))$coefficients
```



---
# Salaire moyen et niveau de diplôme

&nbsp;

.middle[
```{r, echo = F, fig.width = 12, fig.height = 6}
plot_1 = g_wage_educ_avg +
    #ylim(11, 12.7) +
    theme_minimum

plot_1
```
]

---
# Salaire moyen et niveau de diplôme

&nbsp;

.middle[
```{r, echo = F, fig.width = 12, fig.height = 6} 
plot_2 = g_wage_educ_avg +
    theme_minimum +
  geom_abline(intercept = beta_0, slope = beta_1, color = "#dd0747", size = 1, alpha = 0.9) +
  theme_minimum
plot_2
```
]


---
# Salaire moyen et niveau de diplôme

&nbsp;

**Question**: Que se passe t-il quand on considère `educ` comme une variable discrète et non continue?    
     
--

.center[
*hint*: utiliser `as.factor(educ)`
]



--

&nbsp;

**Question**: Est-ce que $\hat{\beta_1}$ représente l'**effet causal** du niveau de diplôme sur le salaire?




---
class: clearinverse
background-color:   #d7e2d8

&nbsp;

# Recap: Régression linéaire simple

**Data**: Données observationnelles

<span style="color:#9933FF">**Hypothèse d'identification**</span>: $\color{#9933FF}{\mathbb{E}(\varepsilon_i|x) = 0}$, i.e. $x$ n'est pas corrêlée au terme d'erreur $\varepsilon$
- dit autrement, $x$ est exogène, i.e. il n'y a pas de variable omise/biais de sélection

**Modèle**: pour tout individu $i$, 

$$Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i$$
  
**Estimateur de l'effet causal de $x$ sur $Y$**:

$$\hat{\beta_1} = \frac{Cov(x,y)}{\mathbb{V}(x)}$$

**Implémentation sur `R`**
- `lm` pour estimer les paramètres du modèle
- `summary` pour afficher le résultat de l'estimation
- `coeftest`, argument `vcov = vcovHC(fit, type = 'HC0')` pour obtenir des se robustes à l'hétéroscédasticité
- `stargazer` ou `modelsummary` pour exporter les résultats en une table $\LaTeX$




---
count: false
layout: false
class: center, middle, inverse

# <span style="color:#FAFAFA;">2. Causalité</span>



---
count:false
class: middle, center,  clearinverse
background-color:  #f8cdda

# <span style="color:#dd0747;">2.1. Corrélation *vs* Causalité</span>


---
name: introcausality
# Exogeneité

L'hypothèse d'exogeneité implique que l'estimateur des MCO est non biaisé
  - donc que $\hat{\beta}$ représente l'effet causal de $x$ sur $y$

<span style="color:#dd0747">**Cependant, cette hypothèse est très forte et rarement vérifiée**</span>

<span style="color:#33B8FF">**Biais de Variable Omise/Biais de sélection** (*Omitted Variable Bias - OVB*) : il existe un biais de variable omise lorsqu'une variable qui n'est pas inclue dans le set de variables explicatives (et donc $\in \varepsilon$),       
1) affecte $y$      
2) est correlée à $x_i$ </span>  

**Exemple canonique de l'équation de Mincer**: on cherche à estimer l'effet d'une année de scolarisation supplémentaire sur le salaire: $\text{Wage} = \alpha + \beta \text{Education} + \varepsilon$
  - Problème: l'abilité, la motivation, ne sont pas observées
  - Dans ce cas, le paramètre $\beta$ n'estime pas l'effet *causal* de l'éducation sur le salaire, mais une *corrélation*
  
---
count:false
class: middle, center,  clearinverse
background-color:  #f8cdda

# <span style="color:#dd0747;">2.2. Potential Outcomes Framework</span>
  

---
# Setup

**Neyman, 1923** & **Rubin, 1974**: cadre conceptuel qui aide à penser la causalité. On s'intéresse à la relation entre deux variables:

- une variable d'outcome $Y_i$  
- une variable de traitement (que l'on suppose binaire par simplicité), $$D_i = \left\{ \begin{array}{ll} 1 \; \text{si l'individu} \; i  \; \text{est traîté} \\ 0 \; \text{si l'individu} \; i \; \text{ n'est pas est traîté}  \end{array} \right.$$

&nbsp;

On cherche estimer l'**effet de $D_i$ sur $Y_i$**, par exemple:
- l'effet d'avoir un master sur le salaire (*returns to education*)
- l'effet d'une peine de prison sur la probabilité de récidive
- l'effet d'un médicament sur la santé d'un patient
- l'effet d'appartenir à une fratrie de plus de 2 enfants sur la réussite scolaire


---
# Outcomes potentiels

Chaque individu $i$ a deux outcomes potentiels:
- $Y_{1i}$ si $D_i = 1$, l'outcome en cas de traitement
- $Y_{0i}$ si $D_i = 0$, l'outcome en l'absence de traitement

L'effet causal du traitement pour chaque individu $i$ est simplement la différence entre l'outcome en cas de traitement et l'outcome en l'absence de traitement:

$$\delta_i = Y_{1i} - Y_{0i}$$
L'espérance des $\delta_i$ donne l'effet **moyen** du traitement (**A**verage **T**reatment **E**ffect):

<span style="color:#dd0747"> $$\text{ATE} = \mathbb{E}(\delta_i) = \mathbb{E}(Y_{1i}) - \mathbb{E}(Y_{0i})$$ </span>


---
# Contrefactuel non observable

&nbsp;

.center[
`r emo::ji("rotating_light")` <span style="color:#dd0747"> **Problème fondamental de l'inférence causale: il n'est pas possible d'observer à la fois $\color{#dd0747}{\text{Y}_{1i}}$ et $\color{#dd0747}{\text{Y}_{0i}}$**</span> `r emo::ji("rotating_light")`
]

&nbsp;

On observe uniquement $Y_i = Y_{1i} D_i + Y_{0i}(1 - D_i)$:
- quand l'individu $i$ est traîté, i.e. $D_i = 1$, on observe uniquement $Y_i = Y_{1i}$
- quand l'individu $i$ n'est pas traîté, i.e. $D_i = 0$, on observe uniquement $Y_i = Y_{0i}$

$\implies$ on observe **deux groupes**: le groupe des individus **traités** et le groupe des individus **non traîtés (ou témoins ou contrôles)**




---
# Différence de moyennes

&nbsp;

<span style="color:#dd0747">**Question:**</span> que peut-on faire à partir des données que l'on observe sur ces deux groupes ?
 
--

&nbsp;

<span style="color:#dd0747">**Réponse:**</span> calculer la différence entre l'outcome moyen des individus traîtés et l'outcome moyen des individus non traîtés, 

$$\Delta = \mathbb{E}(Y_{1i} | D_i = 1) - \mathbb{E}(Y_{0i} | D_i = 0)$$ 
 
 
---
name: potential
# Différence de moyennes = effet causal?

&nbsp;

<span style="color:#dd0747">**Question:**</span> est-ce que $\Delta$ = ATE, l'effet causal moyen du traitement ?

--

&nbsp;

<span style="color:#dd0747">**Réponse: si le traitement n'est pas corrêlé à l'outcome**</span>

Intuition: 
- si le **le traitement est indépendant de l'outcome**, i.e. si le groupe de contrôle est comparable au groupe de traités, ou formellement si $(Y_{1i}, Y_{0i}) \perp D_i$,
- alors il n'y a pas de biais de sélection dans le traitement,
- donc **la différence entre l'outcome moyen du groupe des individus traîtés et celui des individus non traîtés estime l'effet causal du traitement (ATE)**:
$$\Delta = \mathbb{E}(Y_{1i} | D_i = 1) - \mathbb{E}(Y_{0i} | D_i = 0) = \text{ATE} \;\; \text{iff} \;\; (Y_{1i}, Y_{0i}) \perp D_i$$ 

[Maths](#mathpotential)


---
# Sélection

<span style="color:#dd0747">Problème </span>: $\mathbb{E}(Y_{0i} | D_i = 1) = \mathbb{E}(Y_{0i} | D_i = 0)$ (= absence de sélection) est une hypothèse forte. Souvent les groupes traités et non traîtés ne sont pas comparables (étudiants qui décident de faire un master sont peut-être plus motivés, les individus incarcérés sûrement plus dangereux, etc, **inobservable**).

&nbsp;

Différents *types* de sélection:

- **Auto-selection**:
  - si les gains espérés du traitement sont corrêlés à l'outcome 
  - si les coûts liés au traitement sont hétérogènes

- **Selection par les entités qui délivrent le traitement**:
  - si seuls les individus ayant un outcome initial faible sont traîtés
  - ou l'inverse

---
class: clearinverse
background-color:  #f19bb5

&nbsp;

# Application

`r countdown(minutes = 4, top = 0)`

Voici le code pour simuler un jeu de données. Il comprend 10 000 individus, deux variables d'outcome potentiel $Y_0$ et $Y_1$, une variable de traitement D:

```{r, echo = T, include = T}
set.seed(123) # pour la reproductibilité
n = 10000 # nombre d'individus
ATE = 3 

# Outcomes potentiels
Y0 = rnorm(n, mean = 10, sd = 2)  # outcome potentiel en cas de traitement
Y1 = Y0 + rnorm(n, mean = ATE, sd = 1)  # outcome potentiel en l'absence de traitement

# Traitement non aléatoire
D = ifelse(Y0 > median(Y0), 1, 0)

# Outcome observé
Y = Y1*D + Y0*(1-D)  
```

Calculer:   
  - $\Delta$  
  - l'ATT
  - le biais de sélection   
  

---
class: clearinverse
background-color:  #fbe6ec

&nbsp;

# Solution   

```{r, echo = T, include = T}
head(data.frame(Y0, Y1, D, Y))
```

  
---
class: clearinverse
background-color:  #fbe6ec

&nbsp;
# Solution   

```{r, echo = T, include = T}
SD = mean(Y1[D == 1]) - mean(Y0[D == 0])
ATT = mean(Y1[D==1] - Y0[D==1])
bias = mean(Y0[D == 1]) - mean(Y0[D == 0])

# Afficher les résultats
data.frame(
  Delta = SD,
  ATT = ATT,
  Biais_de_selection = bias
)
```



---
count: false
layout: false
class: center, middle, inverse

# <span style="color:#FAFAFA;">3. Randomized Controlled Trials (RCTs)</span>



---
count:false
class: middle, center,  clearinverse
background-color:  #f8cdda

# <span style="color:#dd0747;">3.1. Suppression du biais de sélection</span>


---
# Randomisation

La **randomisation** permet d'éliminer le biais de sélection en allouant aléatoirement les individus au groupe de contrôle et au gorupe de traitement.

Formellement, cela signifie que $(Y_{1i}, Y_{0i}) \perp D_i \;\; \implies \mathbb{E}(Y_{0i} | D_i = 1) = \mathbb{E}(Y_{0i} | D_i = 0)$. 

Donc, $$\begin{align} \text{Biais de Sélection} &= \mathbb{E}(Y_{0i} | D_i = 1) - \mathbb{E}(Y_{0i} | D_i = 0) \\ &= 0 \end{align}$$

Les expériences aléatoires contrôlées, ou ***Randomized Controlled Trials (RCT)***, permettent ainsi d'estimer l'effet causal d'un traitement
  - Très répandues en médecine 
  - De plus en plus répandues (et reconnues) en économie pour l'évaluation des politiques publiques (Prix Nobel par Esther Duflo, Abhijit Banerjee et Michael Kremer en 2019)
  

---
count:false
class: middle, center,  clearinverse
background-color:  #f8cdda

# <span style="color:#dd0747;">3.2. Exemple: le projet STAR</span>


---
# STAR

<span style="color:#dd0747">**Krueger, A. B.** </span> "Experimental estimates of education production functions.", QJE 1999   


Le projet **STAR** (*Student-Teacher Achievement Ratio*) est un exemple très connu d'expériementation qui a pour but d'estimer l'**effet causal de la taille des classes sur les performances scolaires des élèves**.

Principaux éléments:
- 11 600 élèves de l'état du Tennessee ont participé à l'expérimentation
- l'expériementation a débutée l'année scolaire 1985-1986 et concerne des élèves de la GS au CE2 
- **Trois groupes de traitement**:
   - assigmement à une classe de petite taille, de 13 à 17 élèves
   - assignement à une classe de taille moyenne, de 22 à 35 élèves (= groupe de contrôle)
   - assignement à une classe de taille moyenne, de 22 à 35 élèves + aide d'un professeur à temps plein
- élèves et enseignants répartis aléatoirement, à l'échelle d'une école, dans ces trois types de classes
- chaque année les compétences en maths et lecture des élèves sont évaluées


---
name: star
class: clearinverse
background-color:  #f19bb5

&nbsp;

# Application: le projet STAR

`r countdown(minutes = 5, top = 0)`

La réplication des résultats de cette expérimentation est possible grâce à la mise à disposition des données directement sur `R`, à l'aide du package `AER` (pour Applied Econometrics with `R`). [Variables details](#variables)

```{r, echo = T, include = T}
#install.packages("AER") 
library(AER)

data(STAR)

head(STAR)
```


---
class: clearinverse
background-color:  #f19bb5

&nbsp;

# Application: le projet STAR

### Intuition:
1) En l'absence de randomisation, pourquoi simplement comparer les résultats moyens des élèves de petites classes et de classes de taille moyenne ne suffit pas à estimer un effet causal de la taille des classes ?

### Code

**NB: Aide pour calculer les percentiles**.

2) Représenter graphiquement la densité de `avg_perc` pour le groupe *small* et le groupe *regular + regular-with-aide* (Reproduction de la Figure 1, Panel Kindergarten, page 509)

3) Estimer les paramètres du modèle : $Y_i = \beta_0 + \beta_1 \text{Small}_i + \beta_2 \text{RegularAide}_i + \varepsilon_i$ (Reproduction de la Table 5, Colonne 1 page 512)   

---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Data Cleaning   

*In each grade level the regular and regular/aide students were pooled together, and students were assigned percentile scores based on their raw test scores, ranging from 0 (lowest score) to 100 (highest score). A separate percentile distribution was generated for each subject test (e.g. _Math-STA_, _Reading-SAT_, _Word-SAT_, etc). For each test I then determined where in the distribution of the regular-class students every student in the small classes would fall, and students in the small classes were assigned these percentiles scores. Finally, to summarize overall achievement, the average of the _three_ SAT percentile rankings was calculated.*

```{r}

STAR = STAR %>%
  mutate(
    group = ifelse(as.character(stark) == "regular+aide", "regular", as.character(stark)), 
    readk_perc = case_when(
      group == "regular" ~ ecdf(readk[group == "regular"])(readk) * 100, 
      group == "small"   ~ ecdf(readk[group == "regular"])(readk) * 100),
    mathk_perc = case_when(
      group == "regular" ~ ecdf(mathk[group == "regular"])(mathk) * 100,  
      group == "small"   ~ ecdf(mathk[group == "regular"])(mathk) * 100),
    avg_perc = (readk_perc + mathk_perc)/2
  )
```

---
class: clearinverse
count: false
background-color:   #fbe6ec

&nbsp;

# Data Cleaning   

*In each grade level the **regular and regular/aide students were pooled together**, and students were assigned percentile scores based on their raw test scores, ranging from 0 (lowest score) to 100 (highest score). A separate percentile distribution was generated for each subject test (e.g. _Math-STA_, _Reading-SAT_, _Word-SAT_, etc). For each test I then determined where in the distribution of the regular-class students every student in the small classes would fall, and students in the small classes were assigned these percentiles scores. Finally, to summarize overall achievement, the average of the _three_ SAT percentile rankings was calculated.*

```{r}

STAR = STAR %>%
  mutate(
    group = ifelse(as.character(stark) == "regular+aide", "regular", as.character(stark)), #<<
    readk_perc = case_when(
      group == "regular" ~ ecdf(readk[group == "regular"])(readk) * 100, 
      group == "small"   ~ ecdf(readk[group == "regular"])(readk) * 100),
    mathk_perc = case_when(
      group == "regular" ~ ecdf(mathk[group == "regular"])(mathk) * 100,  
      group == "small"   ~ ecdf(mathk[group == "regular"])(mathk) * 100),
    avg_perc = (readk_perc + mathk_perc)/2
  )
```

---
class: clearinverse
count: false
background-color:   #fbe6ec

&nbsp;

# Data Cleaning   

*In each grade level the regular and regular/aide students were pooled together, and students were assigned percentile scores based on their raw test scores, ranging from 0 (lowest score) to 100 (highest score). A **separate percentile distribution was generated for each subject test (e.g. _Math-STA_, _Reading-SAT_, _Word-SAT_, etc). For each test I then determined where in the distribution of the regular-class students every student in the small classes would fall**, and students in the small classes were assigned these percentiles scores. Finally, to summarize overall achievement, the average of the _three_ SAT percentile rankings was calculated.*

```{r}

STAR = STAR %>%
  mutate(
    group = ifelse(as.character(stark) == "regular+aide", "regular", as.character(stark)),
    readk_perc = case_when(
      group == "regular" ~ ecdf(readk[group == "regular"])(readk) * 100, #<<
      group == "small"   ~ ecdf(readk[group == "regular"])(readk) * 100),
    mathk_perc = case_when(
      group == "regular" ~ ecdf(mathk[group == "regular"])(mathk) * 100, #<<
      group == "small"   ~ ecdf(mathk[group == "regular"])(mathk) * 100),
    avg_perc = (readk_perc + mathk_perc)/2
  )
```

---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Data Cleaning   

*In each grade level the regular and regular/aide students were pooled together, and students were assigned percentile scores based on their raw test scores, ranging from 0 (lowest score) to 100 (highest score). A separate percentile distribution was generated for each subject test (e.g. _Math-STA_, _Reading-SAT_, _Word-SAT_, etc). For each test I then determined where in the distribution of the regular-class students every student in the small classes would fall, and **students in the small classes were assigned these percentiles scores**. Finally, to summarize overall achievement, the average of the _three_ SAT percentile rankings was calculated.*

```{r}

STAR = STAR %>%
  mutate(
    group = ifelse(as.character(stark) == "regular+aide", "regular", as.character(stark)),
    readk_perc = case_when(
      group == "regular" ~ ecdf(readk[group == "regular"])(readk) * 100, 
      group == "small"   ~ ecdf(readk[group == "regular"])(readk) * 100), #<<
    mathk_perc = case_when(
      group == "regular" ~ ecdf(mathk[group == "regular"])(mathk) * 100, 
      group == "small"   ~ ecdf(mathk[group == "regular"])(mathk) * 100), #<<
    avg_perc = (readk_perc + mathk_perc)/2
  )
```


---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Data Cleaning   

*In each grade level the regular and regular/aide students were pooled together, and students were assigned percentile scores based on their raw test scores, ranging from 0 (lowest score) to 100 (highest score). A separate percentile distribution was generated for each subject test (e.g. _Math-STA_, _Reading-SAT_, _Word-SAT_, etc). For each test I then determined where in the distribution of the regular-class students every student in the small classes would fall, and students in the small classes were assigned these percentiles scores. Finally, to **summarize overall achievement, the average of the _three_ SAT percentile rankings was calculated**.*

```{r}

STAR = STAR %>%
  mutate(
    group = ifelse(as.character(stark) == "regular+aide", "regular", as.character(stark)),
    readk_perc = case_when(
      group == "regular" ~ ecdf(readk[group == "regular"])(readk) * 100, 
      group == "small"   ~ ecdf(readk[group == "regular"])(readk) * 100),
    mathk_perc = case_when(
      group == "regular" ~ ecdf(mathk[group == "regular"])(mathk) * 100, 
      group == "small"   ~ ecdf(mathk[group == "regular"])(mathk) * 100),
    avg_perc = (readk_perc + mathk_perc)/2 #<<
  )
```

---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution   

### Intuition

1) En l'absence de randomisation, pourquoi simplement comparer les résultats des élèves de petites classes et de classes de taille moyenne ne suffit pas à estimer un effet causal de la taille des classes ?


--

&nbsp;


**Within School sorting**: L'allocation des élèves et professeurs **au sein** des écoles n'est pas aléatoire  
- les élèves les plus en difficultés peuvent-être volontairement placés dans des classes plus petites 
    - auquel cas l'abilité de l'élève, que l'on observe pas, est correlée à la taille des classes, et est également intrinsèquement liée à ses performances scolaires
    - donc l'effet de la taille des classes peut refléter l'effet de l'abilité initiale 
- les enseignants les plus expérimentés peuvent vouloir préférer enseigner dans les classes les plus petites au sein des écoles
  
  
---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution  

2) Représenter graphiquement la densité de `avg_perc` pour le groupe *small* et le groupe *regular + regular-with-aide* (Reproduction de la Figure 1, Panel Kindergarten, page 509)

.pull-left[
```{r,  fig.dim = c(5.5, 3)}

STAR %>% 
  ggplot(aes(x = avg_perc, color = stark, fill = stark)) + 
  geom_density(alpha = 0.4) +  
  labs(title = "Densité de avg_perc par stark",
       x = "",
       y = "Densité") +
  theme_minimal()

```
]

.pull-right[
```{r,  fig.dim = c(5.5, 3)}

STAR %>% 
  ggplot(aes(x = avg_perc, color = group, fill = group)) + 
  geom_density(alpha = 0.4) +  
  labs(title = "Densité de avg_perc par group",
       x = "",
       y = "Densité") +
  theme_minimal()

```
]
  
    
---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution   

3) Estimer les paramètres du modèle : $Y_i = \beta_0 + \beta_1 \text{Small}_i + \beta_2 \text{RegularAide}_i + \varepsilon_i$ (Reproduction de la Table 5, Colonne 1 page 512)  

```{r,  fig.dim = c(5.5, 3)}

STAR = STAR %>% 
  mutate(smallk = ifelse(as.character(stark == "small"), 1, 0),
         regularaidek = ifelse(as.character(stark == "regular+aide"), 1, 0))

summary(lm(avg_perc ~ smallk + regularaidek, data = STAR)) # coeftest(lm(avg_perc ~ smallk + regularaidek, data = STAR), vcov = sandwich)
```


---
count:false
class: middle, center,  clearinverse
background-color:  #f8cdda

# <span style="color:#dd0747;">3.3. Limites</span>


---
# Limites

Bien qu'il s'agisse d'une stratégie empirique très ***clean***, les expériences aléatoires comportent des limites:
- **Coût**:
  - Financier: coût de mise en place de la politique (ex: projet STAR = $12 million)
  - Durée: design de l'expérimentation, validation par l'ERB, pilote, durée du traitement, analyse des résultats (ex: projet STAR a duré 4 ans)
  
- **Validité externe**: les expérimentations sont souvent réalisées à une échelle très locale. Dans quelle mesure les résultats se généralisent à d'autres contextes? Quid du passage à l'échelle?

- Ethique: 
  - une partie de la population "privée" du traitement
  - Quel accompagnement après le traitement?


---
class: clearinverse
background-color:  #d7e2d8

&nbsp; 

# Recap: Randomized Controlled Trial

**Data**: Données expérimentales

<span style="color:#9933FF">**Hypothèse d'identification**:  </span>
- <span style="color:#9933FF"> Intuition: allocation aléatoire du statut de traitement </span>
- <span style="color:#9933FF"> Formellement: $\color{#9933FF}{(Y_{1i}, Y_{0i}) \perp D_i}$ </span>

**Modèle**: pour tout individu $i$,
$$Y_i = \alpha + \delta D_i + \varepsilon$$

**Estimateur de l'effet du traitement**:
- Différence entre l'outcome moyen du groupe des individus traîtés et celui du groupe de contrôle
- $\hat{\delta} = \mathbb{E}(Y_i | D_i = 1) - \mathbb{E}(Y_i | D_i = 0)$

**Implémentation sur `R`**: 
- Balancing Tests: test de différences de moyennes 
- Estimation de l'effet du traitement: `lm(y ~ D, data = data)`







---
class: clearinverse
background-color: #f19bb5

&nbsp;

# Application 

`r countdown(minutes = 2, top = 0)`

Voici le code utilisé dans la précédente application auquel on ajoute une variable `D_random` qui distribue aléatoirement le traitement $D$.

```{r, echo = T, include = T}

set.seed(123) # pour la reproductibilité
n = 10000 # nombre d'individus
ATE = 3 
Y0 = rnorm(n, mean = 10, sd = 2)  # outcome potentiel en cas de traitement
Y1 = Y0 + rnorm(n, mean = ATE, sd = 1)  # outcome potentiel en l'absence de traitement
D = ifelse(Y0 > median(Y0), 1, 0)
Y = Y1*D + Y0*(1-D)  

# Traitement aléatoire
D_random = rbinom(n, 1, 0.5)
Y_random = Y1*D_random + Y0*(1-D_random)
```

Calculer:   
  - <span style="color:grey"> $\Delta$ avec `D`   </span> 
  - <span style="color:grey"> l'ATT </span> 
  - <span style="color:grey"> le biais de sélection   </span> 
  - $\Delta$ avec `D_random`
  

---
class: clearinverse
background-color:   #fbe6ec

&nbsp;

# Solution   

```{r, echo = T, include = T}

SDO = mean(Y[D == 1]) - mean(Y[D == 0])
ATT = mean(Y1[D_random == 1] - Y0[D_random == 1])
bias = mean(Y0[D_random == 1]) - mean(Y0[D_random == 0])
SD_random = mean(Y1[D_random == 1]) - mean(Y0[D_random == 0])

# Afficher les résultats
data.frame(
  Delta = SD,
  ATT = ATT,
  Biais_de_selection = bias,
  Random_diff = SD_random
)
```


---
# Sources

[Econometrics with R](https://www.econometrics-with-r.org/13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html)    
[Project STAR: Student-Teacher Achievement Ratio in AER](https://rdrr.io/cran/AER/man/STAR.html)    
[Causal inference: The Mixtape, Scott Cunningham](https://mixtape.scunning.com/04-potential_outcomes)    
[Florian Oswald](https://raw.githack.com/ScPoEcon/ScPoEconometrics-Slides/master/chapter_slr/chapter_slr.html)               
[Edward Rubin](https://github.com/edrubin/EC421S19/tree/master)               
[Scott Cunningham](https://mixtape.scunning.com)               
[Scientific Research and Methodology, Peter K. Dunn](https://bookdown.org/pkaldunn/Book/)               
Économétrie: méthodes et applications. Bruno Crépon et Nicolas Jacquemet


---
count: false
layout: false
class: center, middle, inverse

# <span style="color:#FAFAFA;">Annexe</span>


---
count:false
name: randomsample
# $\hat{\beta}$ est une variable aléatoire



.pull-left[
```{R, scatter1, echo = F, fig.fullwidth = T, dev = "svg", fig.width = 6, fig.height = 5}
ggplot(data = df_simulation, aes(x = x, y = y)) +
geom_abline( intercept = lm0$coefficients[1], slope = lm0$coefficients[2], color = "#dd0747", size = 1) +
geom_point(color = "black", size = 3) +
theme_empty
```
]

--

.pull-left[
```{R, sample1 scatter, echo = F, fig.fullwidth = T, dev = "svg", fig.width = 6, fig.height = 5}
ggplot(data = df_simulation, aes(x = x, y = y)) +
geom_abline(intercept = lm0$coefficients[1], slope = lm0$coefficients[2], color = "#dd0747", size = 1, alpha = 0.3) +
geom_point(aes(shape = s1), color = "black", size = 3) +
geom_abline( intercept = lm1$coefficients[1], slope = lm1$coefficients[2], size = 1, linetype = 2, color = "black") +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```
]

[Tiré du cours d'Edward Rubin](#https://raw.githack.com/edrubin/EC421S19/master/LectureNotes/02Review/02_review.html#1)

---
count:false
# $\hat{\beta}$ est une variable aléatoire

.pull-left[

```{R, scatter1 opur sample 2, echo = F, fig.fullwidth = T, dev = "svg",  fig.width = 6, fig.height = 5}
ggplot(data = df_simulation, aes(x = x, y = y)) +
geom_abline(intercept = lm0$coefficients[1], slope = lm0$coefficients[2],color = "#dd0747", size = 1) +
geom_point(color = "black", size = 3) +
theme_empty
```


]


.pull-left[

```{R, sample2 scatter, echo = F, fig.fullwidth = T, dev = "svg",  fig.width = 6, fig.height = 5}
ggplot(data = df_simulation, aes(x = x, y = y)) +
geom_abline( intercept = lm0$coefficients[1], slope = lm0$coefficients[2], color = "#dd0747", size = 1, alpha = 0.3) +
geom_point(aes(shape = s2), color = "black", size = 3) +
geom_abline(intercept = lm1$coefficients[1], slope = lm1$coefficients[2],size = 1, linetype = 2, color = "black", alpha = 0.3) +
geom_abline(intercept = lm2$coefficients[1], slope = lm2$coefficients[2],size = 1, linetype = 2, color = "black") +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```
]

[Tiré du cours d'Edward Rubin](#https://raw.githack.com/edrubin/EC421S19/master/LectureNotes/02Review/02_review.html#1)

---
count:false
# $\hat{\beta}$ est une variable aléatoire

.pull-left[

```{R, scatter1 opur sample 3, echo = F, fig.fullwidth = T, dev = "svg", fig.width = 6, fig.height = 5}
ggplot(data = df_simulation, aes(x = x, y = y)) +
geom_abline(intercept = lm0$coefficients[1], slope = lm0$coefficients[2],color = "#dd0747", size = 1) +
geom_point(color = "black", size = 3) +
theme_empty
```
]


.pull-left[

```{R, sample3 scatter, echo = F, fig.fullwidth = T, dev = "svg", fig.width = 6, fig.height = 5}
ggplot(data = df_simulation, aes(x = x, y = y)) +
geom_abline(intercept = lm0$coefficients[1], slope = lm0$coefficients[2],color = "#dd0747", size = 1, alpha = 0.3) +
geom_point(aes(shape = s3), color = "black", size = 3) +
geom_abline(intercept = lm1$coefficients[1], slope = lm1$coefficients[2],size = 1, linetype = 2, color = "darkgrey", alpha = 0.3) +
geom_abline(intercept = lm2$coefficients[1], slope = lm2$coefficients[2],size = 1, linetype = 2, color = "darkgrey", alpha = 0.3) +
geom_abline(intercept = lm3$coefficients[1], slope = lm3$coefficients[2],size = 1, linetype = 2, color = "black") +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```
]

[Tiré du cours d'Edward Rubin](#https://raw.githack.com/edrubin/EC421S19/master/LectureNotes/02Review/02_review.html#1)

---
count:false
# $\hat{\beta}$ est une variable aléatoire

.pull-left[
```{R, simulation, echo = F, fig.fullwidth = T, dev = "svg", fig.width = 6, fig.height = 5}
# simulations
simulate_regression <- function(seed, df_simulation, n_sample) {
  set.seed(seed)
  sample_df_simulation <- df_simulation %>% sample_n(n_sample)
  model <- lm(y ~ x, data = sample_df_simulation)
  coefs <- coef(model)
  return(data.frame(intercept = coefs[1], slope = coefs[2]))
}

# Effectuer les simulations en parallèle
results <- do.call(rbind, mclapply(1:10000, simulate_regression, df = df_simulation, n_sample = n_sample, mc.cores = parallel::detectCores()))

# Tracer les résultats
ggplot() +
  geom_abline(data = results, aes(intercept = intercept, slope = slope), alpha = 0.01, color = "black") +
  geom_point(data = df_simulation, aes(x = x, y = y), size = 3, color = "black", alpha = 0.8) +
  geom_smooth(data = df_simulation, aes(x = x, y = y), method = "lm", color = "#dd0747", se = FALSE, size = 1) +
  theme_empty

```

[Tiré du cours d'Edward Rubin](#https://raw.githack.com/edrubin/EC421S19/master/LectureNotes/02Review/02_review.html#1)        

[Back](#hypothesis)       
]

--

.pull-right[

- En **moyenne**, les droites de régressions sur les échantillons sont très proches de la droite de régression sur l'ensemble de la population


- Mais certaines en sont très éloignées


- ** $\hat{\beta}$ est une variable aléatoire : sa valeur est propre à l'échantillon sur lequel il est estimé**


$\implies$ Tout l'enjeu pour l'économètre est d'assurer que l'échantillon est aléatoire et/ou représentatif de telle sorte à ce que $\hat{\beta}$ soit proche de $\beta$

`r emo::ji("rotating_light")` Bien lire la description de l'échantillon et utiliser les variables de **pondération** lorsque cela est nécessaire!

]




---
count:false
# Échantillon non représentatif/aléatoire

&nbsp;

```{r representative, echo = F, dev = "svg",fig.width = 12, fig.height = 6}

ggplot(data = df_simulation, aes(x = x, y = y)) +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#dd0747", size = 1, alpha = 0.9) +
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty 
```


---
count:false
# Échantillon non représentatif/aléatoire

&nbsp;


```{r non representative,  echo = F, dev = "svg",fig.width = 12, fig.height = 6}
selected_sample = df_simulation %>% filter(y > quantile(y, 0.75)) %>% mutate(selected = "Selected")
df_simulation = df_simulation %>% mutate(selected = ifelse(x %in% selected_sample$x & y %in% selected_sample$y, "Selected", "not selected"))
b0_selected = (lm(y ~ x, data = selected_sample))$coefficients[1]
b1_selected = (lm(y ~ x, data = selected_sample))$coefficients[2]

ggplot() +
    geom_point(data = df_simulation, aes(x = x, y = y, shape = selected), size = 3, color = "black", alpha = 0.8) +
    scale_shape_manual(values = c("Selected" = 19, "not selected" = 1)) +
    #geom_smooth(data = selected_sample, aes(x = x, y = y), method = "lm", color = "#921539", se = FALSE, size = 1, fullrange = TRUE) +
    geom_abline(intercept = b0_selected, slope = b1_selected, color = "#921539", size = 1, alpha = 0.9) +
    #geom_abline(intercept = b0, slope = b1, color = "#dd0747", size = 1, alpha = 0.9) +
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty
```



---
count:false
# Échantillon non représentatif/aléatoire

&nbsp;


```{r non representative 2 lines,  echo = F, dev = "svg", fig.width = 12, fig.height = 6}
selected_sample = df_simulation %>% filter(y > quantile(y, 0.75)) %>% mutate(selected = "Selected")
df_simulation = df_simulation %>% mutate(selected = ifelse(x %in% selected_sample$x & y %in% selected_sample$y, "Selected", "not selected"))
b0_selected = (lm(y ~ x, data = selected_sample))$coefficients[1]
b1_selected = (lm(y ~ x, data = selected_sample))$coefficients[2]

ggplot() +
    geom_point(data = df_simulation, aes(x = x, y = y, shape = selected), size = 3, color = "black", alpha = 0.8) +
    scale_shape_manual(values = c("Selected" = 19, "not selected" = 1)) +
    #geom_smooth(data = selected_sample, aes(x = x, y = y), method = "lm", color = "#921539", se = FALSE, size = 1, fullrange = TRUE) +
    geom_abline(intercept = b0_selected, slope = b1_selected, color = "#921539", size = 1, alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#dd0747", size = 1, alpha = 0.9) +
    scale_x_continuous(limits = c(-1,8)) +
    scale_y_continuous(limits = c(0.5,7)) +
    theme_empty
```


[Back](#hypothesis)


---
count:false
name: outliers
# Outliers

&nbsp;


```{r no outliers, echo = F, dev = "svg", fig.width = 12, fig.height = 6}
ggplot(data = df_simulation, aes(x = x, y = y)) +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    geom_abline(intercept = b0, slope = b1, color = "#dd0747", size = 1, alpha = 0.9) +
    scale_x_continuous(limits = c(-1,11)) +
    scale_y_continuous(limits = c(0.5,41)) +
    theme_empty 
```



---
count:false
# Outliers

&nbsp;

```{r point outlier, echo = F, dev = "svg",fig.width = 12, fig.height = 6}
df_with_outlier <- rbind(df_simulation %>% select(x,y,selected), data.frame(x = 10, y = 40, selected = "Outlier"))
b0_outliers = (lm(y ~ x, data = df_with_outlier))$coefficients[1]
b1_outliers = (lm(y ~ x, data = df_with_outlier))$coefficients[2]

ggplot(data = df_with_outlier, aes(x = x, y = y)) +
    geom_point(size = 3, color = "black", alpha = 0.9) +
    #geom_abline(intercept = b0, slope = b1, color = "#dd0747", size = 1, alpha = 0.9) +
    scale_x_continuous(limits = c(-1,11)) +
    scale_y_continuous(limits = c(0.5,41)) +
    theme_empty 
```


---
count:false
# Outliers

&nbsp;

```{r outliers, echo = F, echo = F, dev = "svg", fig.width = 12, fig.height = 6}

ggplot(data = df_with_outlier, aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_abline(intercept = b0_outliers, slope = b1_outliers, color = "#921539", size = 1, alpha = 0.9) +
  scale_x_continuous(limits = c(-1,11)) +
  scale_y_continuous(limits = c(0.5,41)) +
  theme_empty

```


---
count:false
# Outliers

&nbsp;

```{r outliers 2 lines, echo = F, echo = F, dev = "svg", fig.width = 12, fig.height = 6}

ggplot(data = df_with_outlier, aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_abline(intercept = b0_outliers, slope = b1_outliers, color = "#921539", size = 1, alpha = 0.9) +
  geom_abline(intercept = b0, slope = b1, color = "#dd0747", size = 1, alpha = 0.9) +
  scale_x_continuous(limits = c(-1,11)) +
  scale_y_continuous(limits = c(0.5,41)) +
  theme_empty

```



---
count:false
# Traitement des outliers

&nbsp;

**Solution 1: Supprimer les outliers**
- Identifier les outliers:
  - à partir de l'**écart-type**: *lorsque la distribution des données est relativement symétrique*. Une observation éloignée de plus de 3 $\times$ écart-type de la moyenne peut être considérée comme une valeur abberrante 
  - à partir de l'**écart interquartile**: peut être considérée comme outlier toute observation non incluse dans l'intervalle $[Q_1 - k(Q_3 - Q_1) \;;\; Q3 + k (Q3 - Q1)]$  où $k>0$. On détecte des outliers *moyens* pour $k=1.5$, et *extrêmes* pour $k=3$


**Solution 2: Windsoring**: remplacer les outliers par la valeur du 99ème percentile de la variable


**Solution 3: utiliser le log de la variable**


**Solution 4: ne rien faire**. Parfois certaines observations/individus sont très éloignés de la moyenne.

&nbsp;

[Back](#hypothesis)



---
count:false
name: heteroscedasticity
# Hétéroscédasticité

```{r dataset simulation heteroscedasticity, include = F, cache = T}
set.seed(123)

# Population and sample size
n_population_h = 1000

# True parameters
a = 1.6
b = 0.7

# Regressor and error term
x = rnorm(n_population_h, mean = 3, sd = 1.5)
e = rnorm(n_population_h, mean = 0, sd = 1)
e_heteroscedastic <- rnorm(n_population_h, mean = 0, sd = abs(x)^(1/3))
  
# Outcome
y = a + b*x + e
y_heteroscedastic <- a + b * x + e_heteroscedastic

# Dataframe
df_simulation_h = data.frame(
  a = rep(a, n_population_h),
  b = rep(b, n_population_h),
  x = x,
  e = e,
  y = y,
  e_heteroscedastic = e_heteroscedastic,
  y_heteroscedastic = y_heteroscedastic
)
```

.pull-left[
```{r nuage homoscedastic, echo = F, fig.fullwidth = T, dev = "svg", fig.width = 6, fig.height = 5}

ggplot(data = df_simulation_h, aes(x = x, y = y)) +
  geom_point(size = 3, color = "black", alpha = 0.9) +
  theme_empty 

```
]

.pull-right[
```{r nuage heteroscedastic, echo = F, fig.fullwidth = T, dev = "svg", fig.width = 6, fig.height = 5}
ggplot(data = df_simulation_h, aes(x = x, y = y_heteroscedastic)) +
  geom_point(size = 3, color = "black", alpha = 0.9) +
  theme_empty 

```
]


[Back](#hypothesis2)




---
count:false
name: derivation
# Calcul de l'estimateur des MCO dans le cas univarié

On a : $\text{SCE} = \sum_{i = 1}^N \varepsilon_i^2 = \sum_{i = 1}^N \left( y_i - \hat{y}_i\right)^2  = \sum_{i = 1}^N \left( y_i^2 - 2 y_i \hat{\beta_0} - 2 y_i \hat{\beta_1} x_i + \hat{\beta_0}^2 + 2 \hat{\beta_0} \hat{\beta_1} x_i + \hat{\beta_1}^2 x_i^2 \right)$

Les conditions de premier ordre de la minimisation sont:

.center[
$\dfrac{\partial \text{SSE}}{\partial \hat{\beta_0}} = 0$   **(1)**      et      $\dfrac{\partial \text{SSE}}{\partial \hat{\beta}} = 0$    **(2)**
]

Pour (1):

$$\begin{align} \dfrac{\partial \text{SSE}}{\partial \hat{\beta_0}} = 0 
 \;\;\;\; &\implies \sum_{i = 1}^N \left( 2 \hat{\beta_0} + 2 \hat{\beta_1} x_i - 2 y_i \right) = 2N \hat{\beta_0} + 2 \hat{\beta_1} \sum_{i = 1}^N x_i - 2 \sum_{i = 1}^N y_i = 2N \hat{\beta_0} + 2\hat{\beta} N \overline{x} - 2N \overline{y} = \; 0 \\&\implies \color{#dd0747}{\hat{\beta_0} = \overline{y} - \hat{\beta_1} \overline{x}} \;\;\;\;\;(3)\end{align}$$
 
où 
$\overline{x} = \frac{\sum_{i=1}^N x_i}{n}$ et $\overline{y} = \frac{\sum_{i=1}^N y_i}{N}$ sont les moyennes de $x$ et $y$ sur notre échantillon de taille $n$.


---

Pour (2):

$$\begin{align} 
\dfrac{\partial \text{SSE}}{\partial \hat{\beta}} = 0  \;\;\;\; &\implies \sum_{i = 1}^N \left( 2 \hat{\beta_0} x_i + 2 \hat{\beta_1} x_i^2 - 2 y_i x_i \right) = 2 \hat{\beta_0} N \overline{x} + 2 \hat{\beta_1} \sum_{i = 1}^N x_i^2 - 2 \sum_{i = 1}^N y_i x_i = 0   \;\;\;\;\; (4)\end{align}$$


En remplaçant $\hat{\beta_0}$ par sa valeur définie dans (3), on obtient:
.center[
$2N \left(\overline{y} - \hat{\beta_1} \overline{x}\right) \overline{x} + 2 \hat{\beta} \sum_{i = 1}^N  x_i^2 - 2 \sum_{i = 1}^N  y_i x_i = 0$
]

en développant, 
.center[
$$2N \overline{y} \, \overline{x} - 2N \hat{\beta} \overline{x}^2 + 2 \hat{\beta} \sum_{i = 1}^N  x_i^2 - 2 \sum_{i = 1}^N  y_i x_i = 0 \; \implies \; 2 \hat{\beta} \left( \sum_{i = 1}^N  x_i^2 - N \overline{x}^2 \right) = 2 \sum_{i = 1}^N  y_i x_i - 2N \overline{y}\,\overline{x}$$

$$\implies \color{#dd0747}{\hat{\beta}} = \dfrac{\sum_{i = 1}^N  y_i x_i - N \overline{y}\,\overline{x}}{\sum_{i = 1}^N  x_i^2 - N \overline{x}^2} = \dfrac{\sum_{i = 1}^N  (x_i - \overline{x})(y_i - \overline{y})}{\sum_{i = 1}^N  (x_i - \overline{x})^2}   \color{#dd0747}{=\dfrac{Cov(x,y)}{Var(x)}}$$
]

[Back](#OLS)



---
count:false
name: mathpotential

# ATE

On a $\delta_i = Y_{1i} - Y_{0i}$ que l'on peut réécrire 
$$Y_{1i} = \delta_i + Y_{0i} \;\; \;\; (1)$$ 

Prenons la différence entre <span style="color:#88aa8b">l'outcome moyen des individus traîtés</span> et <span style="color:#9f9cc3">l'outcome moyen des individus non traîtés</span>:

$$\begin{align}\Delta &= \color{#88aa8b}{\mathbb{E}(Y_i | D_i = 1)} - \color{#9f9cc3}{\mathbb{E}(Y_i | D_i = 0)} \\ &= \mathbb{E}(Y_{1i} | D_i = 1) - \mathbb{E}(Y_{0i} | D_i = 0) \end{align}$$
En remplaçant $Y_{1i}$ par sa valeur décrite en (1),

$$\begin{align}\Delta  &= \mathbb{E}(\delta_i + Y_{0i} | D_i = 1) - \mathbb{E}(Y_{0i} | D_i = 0) \\ &= \underbrace{\mathbb{E}(\delta_i| D_i = 1)}_{= \;\text{ATT}} + \underbrace{\mathbb{E}(Y_{0i} | D_i = 1)  - \mathbb{E}(Y_{0i} | D_i = 0)}_{= \;\text{Selection Bias}} \end{align}$$
Donc $\Delta = \text{ATT} + \text{Selection Bias}$.


---
count:false
# ATE

Si <span style="color:#dd0747"> $\color{#dd0747}{D_i}$ n'est pas corrêlé à l'outcome</span>, formellement si $(Y_{1i}, Y_{0i}) \perp D_i$,

Alors $$\mathbb{E}(\delta_i | D_i = 1) = \mathbb{E}(\delta_i)$$

Et $$\mathbb{E}(Y_{0i} | D_i = 1) = \mathbb{E}(Y_{0i} | D_i = 0)$$

Donc $$\color{#dd0747}{\Delta = ATE}$$


[Back](#potential)


---
count:false
name: variables
# Variables STAR 

- `gender`: genre de l'élève,`male` ou `female`
- `ethnicity`: ethnicité de l'élève, `cauc` (caucasien), `afam` (afro-americain), `asian`, hispanic, `amindian` (amerindien), `other`
- `birth`: sous la forme Année de naissance Trimestre de naissance (eg 1998 Q2)
- `stark` à `star3`: groupe de traitement (`small` ou `regular-with-aide`) ou contrôle (`regular`) pour chaque classe du kindergarten (GS) à la grade 3 (CE2). Si `NA`, alors l'élève ne fait pas encore parti/a quitté l'expérience
- `readk` à `read3`: score en lecture, pour chaque classe (k,1,2,3)
- `mathk` à `math3`: score en maths pour, chaque classe (k,1,2,3)
- `lunchk` à `lunch3`: dummy qui indique si l'élève est élègible aux repas gratuits (= proxy pour l'origine sociale), pour chaque classe (k,1,2,3)
- `schoolk` à `school3`: type d'école (`inner-city`, `suburban`, `rural` or `urban`), pour chaque classe (k,1,2,3)
- `degreek` à `degree3`: plus haut niveau de diplôme du professeur (`bachelor`, `master`, `specialist`, `phd`), pour chaque classe (k,1,2,3)
- `ladderk` à `ladder3`: degré d'expérience/statut du professeur (`level1`, `level2`, `level3`, `apprentice`, `probation`, `pending`), pour chaque classe (k,1,2,3)
- `experiencek` à `experience3`: nombre d'années d'expérience du professeur, pour chaque classe (k,1,2,3)
- `tethnicityk` à `tethnicity3`: ethnicité du professeur, `cauc` (caucasien), `afam` (afro-americain), `asian`
- `systemk` à `system3`: identifiant du système scolaire
- `schoolidk` à `schoolid3`: identifiant de l'école   
[Back](#star)




