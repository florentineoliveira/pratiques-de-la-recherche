<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Variables de contr√¥le et matching</title>
    <meta charset="utf-8" />
    <meta name="author" content="Florentine Oliveira" />
    <meta name="date" content="2025-02-18" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Variables de contr√¥le et matching
]
.subtitle[
## Pratiques de la Recherche en √âconomie
]
.author[
### Florentine Oliveira
]
.date[
### 2025-02-18
]

---




layout: true

---
count:false
class: middle, center
background-color: #dd0747

# &lt;span style="color:#FAFAFA;"&gt; Reminder &lt;/span&gt;
---

L'objectif est d'estimer l'effet d'un **traitement** `\(D\)` sur une variable d'**outcome** `\(Y\)`.
  - par exemple l'effet d'avoir un master sur le salaire

&amp;nbsp;

--

Peut-on en d√©duire l'effet du traitement en comparant l'outcome des individus trait√©s √† celui des individus non trait√©s? 
  - par exemple peut-on quantifier l'effet d'avoir un master sur le salaire en comparant les individus qui ont un master √† ceux qui n'en ont pas? 

&amp;nbsp;

--

&lt;span style="color:#dd0747"&gt;**Dans 99,99999% des cas, NON!**: le groupe des trait√©s et celui des contr√¥les ne sont en g√©n√©ral pas comparables&lt;/span&gt; 
  - par exemple, les femmes et les enfants issus de milieux sociaux favoris√©s sont plus susceptibles de faire de hautes √©tudes, et ces caract√©ristiques peuvent aussi influencer le salaire


--

Dans 0,00001% des cas, il est possible de comparer l'outcome moyen des individus trait√©s et des individus t√©moins si le traitement est distribu√© de fa√ßon al√©atoire (RCT; mais cela est tr√®s on√©reux, pose des questions √©thiques, etc.).
  



---
# Cette s√©ance

&amp;nbsp;

1. Mod√®le de r√©gression lin√©aire multivari√©
 
  1.1. Biais de variable omise (OVB)        
  1.2. Hypoth√®ses    
  1.3. Estimateur    
  1.4. Bonnes et mauvaises variables de contr√¥le    
  1.5. Coefficient de d√©termination (R2)

2. Matching

  2.1. Intuition   
  2.2. M√©thodes    

3. Causalit√©

---
count:false
class: middle, center
background-color: #dd0747

# &lt;span style="color:#FAFAFA;"&gt;  1. Mod√®le de r√©gression lin√©aire multivari√© &lt;/span&gt;


---
# 1. Mod√®le de r√©gression lin√©aire multivari√©
## 1.1. Biais de variable omise (OVB)

Notre mod√®le de base s'√©crit   
\begin{equation}
Y_i = \alpha + \beta D_i + \varepsilon_i \;\;\;\;\;\;\;\;\; (1)
\end{equation}


Par exemple, `\(Y_i\)` d√©signe le salaire de l'individu `\(i\)`, `\(D_i\)` une dummy qui repr√©sente le fait d'avoir un master ou non, et `\(\varepsilon_i\)` le terme d'erreur.

--

Supposons qu'il existe une variable `\(W_i\)`, par exemple une variable binaire √©gale √† 1 si `\(i\)` est une Femme.

--

`\(W_i\)` est implicitement contenue dans le terme d'erreur dans le mod√®le (1).

--

Or, les femmes sont en moyenne davantage √©duqu√©es que les hommes.

--

Donc `\(D_i\)` est corr√™l√© √† `\(\varepsilon_i\)`, ou dit autrement `\(\mathbb{E}(\varepsilon_i|D_i) \neq 0\)`

--

.center[üö® &lt;span style="color:#dd0747"&gt; **= Biais de variable omise**&lt;/span&gt; üö®]


---
# 1. Mod√®le de r√©gression lin√©aire multivari√©
## 1.1. Biais de variable omise (OVB)


On a le mod√®le 
`$$Y_i = \alpha + \color{#DC7660}{\beta} D_i + \varepsilon_i$$`

o√π la (ou les) variable `\(W_i\)` est omise (donc appartient √† `\(\varepsilon_i\)`).

La mod√®le *multivari√©* s'√©crit 
$$ Y_i = \gamma + \color{#DC7660}{\delta} D_i + \color{#60DC89}{\phi} W_i + \nu_i$$
On a donc la relation:

`$$\color{#DC7660}{\beta} = \underbrace{\color{#DC7660}{\delta}}_{"vrai" estimateur} + \underbrace{\color{#60DC89}{\phi} \color{#6660DC}{\pi}}_{OVB}$$`
o√π `\(\pi\)` est le coefficient de la r√©gression de `\(W_i\)` sur `\(D_i\)` ( `\(W_i = \lambda + \color{#6660DC}{\pi} D_i\)` )




---
# 1. Mod√®le de r√©gression lin√©aire multivari√©
## 1.1. Biais de variable omise (OVB)

**Exemple tir√© du DM**



&lt;table style="NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;" class="table"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Log(Wage) &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Women &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Log(Wage)  &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 7.282*** &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.442*** &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 7.433*** &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.004) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.004) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.004) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; At least Bac &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.481*** &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.097*** &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.514*** &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.006) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.006) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.006) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Women &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; ‚àí0.341*** &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;box-shadow: 0px 1.5px"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;box-shadow: 0px 1.5px"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;box-shadow: 0px 1.5px"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;box-shadow: 0px 1.5px"&gt; (0.006) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Num.Obs. &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 31835 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 31835 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 31835 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; R2 Adj. &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.173 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.009 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.260 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;&lt;tr&gt;&lt;td style="padding: 0; " colspan="100%"&gt;
&lt;sup&gt;&lt;/sup&gt; * p &amp;lt; 0.1, ** p &amp;lt; 0.05, *** p &amp;lt; 0.01&lt;/td&gt;&lt;/tr&gt;&lt;/tfoot&gt;
&lt;/table&gt;





---
#  1. Mod√®le de r√©gression lin√©aire multivari√©
## 1.2. Hypoth√®ses du mod√®le multivari√©


`\(\color{#9933FF}{H_1}\)` Lin√©arit√©: le mod√®le est lin√©aire dans les param√®tres: `\(\color{#9933FF}{\frac{\partial y_i}{\partial x_{ik}} = \beta_k}\)`,  `\(\color{#9933FF}{\forall k =1, ..., K}\)`
  

`\(\color{#9933FF}{H_2}\)` √âchantillon Al√©atoire: l'√©chantillon est al√©atoire et repr√©sentatif de la population.


.center[
&lt;span style="color:#9933FF"&gt; `\(\color{#9933FF}{H_3}\)` **Exogeneit√© _conditionnelle_**: Conditionnellement aux contr√¥les `\(W\)`, `\(D\)` est exog√®ne&lt;/span&gt; 

  Formellement, `\(\color{#9933FF}{\mathbb{E}(\varepsilon_i|D,W) = 0}\)`   
]

`\(\color{#9933FF}{H_4}\)` Variation: il y a suffisamment de variation dans `\(X\)` o√π `\(X = (1\;\; D \;\;W)\)` 
  - Dit autrement, chaque variable explicative apporte une information qui lui est propre
  - Formellement, les explicatives ne sont pas colin√©aires (cas multivari√©: `\(\color{#9933FF}{(X'X)}\)` &lt;span style="color:#9933FF"&gt;est inversible&lt;/span&gt;)
  
  
`\(\color{#9933FF}{H_5}\)` Les erreurs `\(\varepsilon_i\)` sont sph√©riques: `\(\color{#9933FF}{H_{5a}}\)` homosc√©dasticit√© &amp; `\(\color{#9933FF}{H_{5b}}\)` Absence d'autocorr√©lation


---
#  1. Mod√®le de r√©gression lin√©aire multivari√©
## 1.2. Hypoth√®ses du mod√®le multivari√©

L'hypoth√®se d'ind√©pendance conditionnelle, ou &lt;span style="color:#9933FF"&gt;***Conditional Independance Assumption (CIA)***&lt;/span&gt;, aussi appel√©e s√©lection sur les observables, indique que:
- conditionellement √† des variables explicatives `\(W_i\)`, les outcomes potentiels `\(\{Y_{0i}, Y_{1i}\}\)` sont ind√©pendants du traitement `\(D_i\)`
- dit autrement, en contr√¥lant par les variables `\(W_i\)`, le traitement `\(D_i\)` est *as-good-as random*

&amp;nbsp;

Formellement, dans le framework des outcomes potentiels, l'hypoth√®se d'identification devient:    

`$$\{Y_{0i}, Y_{1i}\} \perp D_i \color{#dd0747}{|W_i}$$` 
On a donc: `$$\begin{align} \text{Biais de S√©lection} &amp;= \mathbb{E}(Y_{0i} |  \color{#dd0747}{W_i}, D_i = 1) - \mathbb{E}(Y_{0i} |  \color{#dd0747}{W_i}, D_i = 0) \\ &amp;= \mathbb{E}(Y_{0i} | \color{#dd0747}{W_i}) -  \mathbb{E}(Y_{0i} | \color{#dd0747}{W_i}) \\ &amp;= 0 \end{align}$$`



---
name:estimateur
#  1. Mod√®le de r√©gression lin√©aire multivari√©
## 1.3. Estimateur dans le cas multivari√©


L'estimateur MCO dans le cas multivari√© s'√©crit:
`$$\hat{\beta} = (X'X)^{-1} X'Y$$`



&lt;button class="inline" onclick="window.location.hash='mathsestimateur'"&gt;Maths&lt;/button&gt;


C'est toujours l'estimateur *BLUE*: **B**est **L**inear **U**nbiased **E**stimator


---
#  1. Mod√®le de r√©gression lin√©aire multivari√©
## 1.4 Bonnes et mauvaises variables de contr√¥le

Une *bonne* variable de contr√¥le doit:   
- contribuer √† **expliquer la variable d√©pendante** 
- par une **information qui lui est propre** 
- **ne pas √™tre impact√©e par le traitement** d'int√©r√™t     

Si elles satisfont ces conditions, les variables de contr√¥le permettent:

- d'att√©nuer le risque de biais de variable omise
- gagner en pr√©cision 




---
name: badcontrol
#  1. Mod√®le de r√©gression lin√©aire multivari√©
## 1.4 Bonnes et mauvaises variables de contr√¥le

Une *mauvaise* variable de contr√¥le est:

Une &lt;span style="color:#33B8FF"&gt; **variable non pertinente** &lt;/span&gt; est une variable qui ne contribue pas √† expliquer l'outcome.
- le param√®tre estim√© sera donc nul üòê
- l'estimateur reste sans biais tant que la variable non pertinente n'est pas corr√©l√©e √† `\(\varepsilon_i\)` üòê
- l'estimateur est moins pr√©cis üò¢


Une &lt;span style="color:#33B8FF"&gt; **variable redondante**&lt;/span&gt; si l'information qu'elle contient est d√©j√† contenue dans une autre variable
- lorsque deux variables sont tr√®s corr√©l√©es, difficile de distinguer l'effet "propre" de chacune, donc les estimateurs de ces deux variables seront tr√®s impr√©cis
- dans le cas extr√™me de colin√©arit√©, le mod√®le n'est pas identifiable üò¢



Un &lt;span style="color:#33B8FF"&gt; **mauvais contr√¥le** (*bad control*)&lt;/span&gt; est une variable qui est √©galement affect√©e par le traitement
- l'estimateur peut √™tre biais√© üò¢



---
# 1.5 Coefficient de d√©termination (R2)

Le coefficient de d√©termination, ou `\(R^2\)`, informe sur la **qualit√©** de la r√©gression lin√©aire, i.e. la **part de la variance de l'outcome expliqu√©e par les `\(X\)`**. 

Formellement, 

`$$\begin{align} R^2 &amp;=  \frac{SCE}{SCT} = \frac{\sum_i (\hat{y_i} - \overline{y}_i)^2}{\sum_i (y_i - \overline{y}_i)^2} \\ &amp;= 1 -  \frac{SCR}{SCT} = 1 - \frac{\sum_i (y_i - \hat{y}_i)^2}{\sum_i (y_i - \overline{y}_i)^2}\end{align}$$`

NB: le `\(R^2\)`
- augmente **m√©caniquement** avec le nombre de varibales explicatives 
  - comparer les `\(R^2\)` ajust√©s lorsqu'on compare diff√©rents mod√®les
  - `\(R^2_{adj} = 1 - (1 - R^2) \frac{N - 1}{N-K-1}\)`
- est sp√©cifique √† un sample
- est tr√®s informatif pour faire de la pr√©diction mais n'informe en rien sur la causalit√© 



---
count:false
class: middle, center
background-color: #dd0747

# &lt;span style="color:#FAFAFA;"&gt;  2. Matching &lt;/span&gt;



---
# 2. Matching
## 2.1. Intuition

Lorsque l'on **contr√¥le** par des observables `\(W\)`, on peut avoir de l'*imbalance* (Ho, Imai, King,Stuart, 2007, Political Analysis)
  
  
&lt;img src="imgs/matching1.png" width="55%" style="display: block; margin: auto;" /&gt;

  
  
  
  
  
---
count:false
# 2. Matching
## 2.1. Intuition

Lorsque l'on **contr√¥le** par des observables `\(W\)`, on peut avoir de l'*imbalance* (Ho, Imai, King,Stuart, 2007, Political Analysis)
  
&lt;img src="imgs/matching2.png" width="55%" style="display: block; margin: auto;" /&gt;
  
---
count:false
# 2. Matching
## 2.1. Intuition

Lorsque l'on **contr√¥le** par des observables `\(W\)`, on peut avoir de l'*imbalance* (Ho, Imai, King,Stuart, 2007, Political Analysis)
  
&lt;img src="imgs/matching3.png" width="55%" style="display: block; margin: auto;" /&gt;

---
count:false
# 2. Matching
## 2.1. Intuition

Lorsque l'on **contr√¥le** par des observables `\(W\)`, on peut avoir de l'*imbalance* (Ho, Imai, King,Stuart, 2007, Political Analysis)
  
&lt;img src="imgs/matching4.png" width="55%" style="display: block; margin: auto;" /&gt;

---
count:false
# 2. Matching
## 2.1. Intuition

Lorsque l'on **contr√¥le** par des observables `\(W\)`, on peut avoir de l'*imbalance* (Ho, Imai, King,Stuart, 2007, Political Analysis)
  
&lt;img src="imgs/matching5.png" width="55%" style="display: block; margin: auto;" /&gt;

---
count:false
# 2. Matching
## 2.1. Intuition

Lorsque l'on **contr√¥le** par des observables `\(W\)`, on peut avoir de l'*imbalance* (Ho, Imai, King,Stuart, 2007, Political Analysis)
  
&lt;img src="imgs/matching6.png" width="55%" style="display: block; margin: auto;" /&gt;


---
count:false
# 2. Matching
## 2.1. Intuition

Lorsque l'on **contr√¥le** par des observables `\(W\)`, on peut avoir de l'*imbalance* (Ho, Imai, King,Stuart, 2007, Political Analysis)

&lt;img src="imgs/matching7.png" width="55%" style="display: block; margin: auto;" /&gt;





---
# 2. Matching
## 2.2. M√©thodes de matching

Les estimateurs de *matching* construisent artificiellement un **groupe** d'individus non tra√Æt√©s qui a les m√™mes caract√©ristiques que le groupe d'individus trait√©s
  - Assure un support commun des variables explicatives
  
Diff√©rents m√©thodes/algorithmes de matching:
- Matching exact: on cherche les individus *strictement identiques* (tr√®s restrictif!)
- *Propensity score matching*: on assigne √† chaque individu une probabilit√© d'√™tre tra√Æt√© et on matche ceux avec des scores proches
- Plus proches voisins (*Nearest neighboors*): on cherche l'individu non-tra√Æt√© le plus proche d'un individu trait√© selon certaines m√©triques
- ...
NB: des combinaisons de m√©thodes sont possibles!

Inconv√©nients:
- certaines observations n'ont pas de match: on estime l'effet de traitement lorsque c'est "faisable"


---
count:false
class: middle, center
background-color: #dd0747

# &lt;span style="color:#FAFAFA;"&gt;  3. Causalit√© &lt;/span&gt;



---
# 3. Causalit√©


Les m√©thodes de **matching** sont des m√©thodes d'identification qui reposent sur la CIA, c'est √† dire que la s√©lection dans le traitement est uniquement li√©e √† des variables **observables** `\(X\)`. 

L'hypoth√®se d'ind√©pendance conditionnelle revient √† dire qu'en **contr√¥lant** (i.e. en "tenant compte de") **par un ensemble de variables `\(X_i\)`**, `\(D\)` est ***as good as random***.

Sous l'hypoth√®se d'ind√©pendance conditionnelle, l'effet estim√© est l'**effet moyen du traitement &lt;span style="color:#dd0747"&gt;conditionnel&lt;/span&gt;** (***Conditional*** **ATE** - CATE)

&amp;nbsp;

En r√©alit√©, il s'agit d'une **hypoth√®se d'identification tr√®s forte**:
- elle suppose d'inclure toutes les variables explicatives `\(X\)` qui expliquent la corr√©lation entre `\(\varepsilon_i\)` et `\(D_i\)`
  - &lt;span style="color:#dd0747"&gt;Probl√®me: nombre de ces variables sont **inobservables**&lt;/span&gt;




---
background-color: #d7e2d8
# Recap: OLS 

&lt;span style="color:#9933FF"&gt;**Hypoth√®se d'identification: CIA**&lt;/span&gt;
- &lt;span style="color:#9933FF"&gt; Intuition: conditionnellement aux catact√©ristiques `\(W\)` par lesquelles on *"contr√¥le"*, le traitement est al√©atoire&lt;/span&gt;
- &lt;span style="color:#9933FF"&gt; Formellement:&lt;/span&gt;, `\(\color{#9933FF}{\mathbb{E}(\varepsilon_i|D_i, W_i) = 0}\)`

**Comparaison**: parmi les individus qui ont les m√™mes caract√©ristiques par lesquelles on contr√¥le, on compare les individus tra√Æt√©s √† ceux qui ne le sont pas.

**Mod√®le**: `\(Y = X \beta + \varepsilon\)`, o√π `\(X = (1DW)\)`

**Estimateur**:  `\(\hat{\beta} = (X'X)^{-1} X'Y\)`

**Impl√©mentation sur `R`**: 
- `lm` pour estimer les param√®tres du mod√®le
- `summary` pour afficher le r√©sultat de l'estimation
- `coeftest`, argument `vcov = vcovHC(fit, type = 'HC0')` pour obtenir des se robustes √† l'h√©t√©rosc√©dasticit√©
- `stargazer` ou `modelsummary` pour exporter les r√©sultats en une table `\(\LaTeX\)`




---
# Sources

[Causal inference: The Mixtape, Scott Cunningham](https://mixtape.scunning.com/05-matching_and_subclassification)         


---
count:false
class: middle, center
background-color: #dd0747

# &lt;span style="color:#FAFAFA;"&gt;  Annexe &lt;/span&gt;



---
name:mathsestimateur
# Estimateur MCO dans le cas multivari√©

Le mod√®le multivari√© s'√©crit: `\(\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; y_i = \beta_1 + \beta_2 D_i + \sum_{k=1}^K w_{ik} \gamma_k + \varepsilon_i\)`  

On peut l'√©crire sous forme matricielle: `\(\;\;\;\;\;\;\;\;\; Y = \beta_1 + \beta_2 D + W \gamma + \varepsilon\)`

o√π `\(W\)` est une matrice contenant les `\(K\)` variables de contr√¥le.

&amp;nbsp;

On peut finalement r√©√©crire le mod√®le:

$$Y =  X \beta + \varepsilon $$

o√π 
`$$X = \begin{bmatrix}
1 &amp; D_1 &amp; W_{1,1} &amp; \cdots &amp; W_{1,K} \\
1 &amp; D_2 &amp; W_{2,1} &amp; \cdots &amp; W_{2,K} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; D_n &amp; W_{n,1} &amp; \cdots &amp; W_{n,K}
\end{bmatrix} \quad \beta =
\begin{bmatrix}
\beta_1 \\
\beta_2 \\
\gamma_1 \\
\vdots \\
\gamma_K
\end{bmatrix} \quad \varepsilon =
\begin{bmatrix}
\varepsilon_1 \\
\varepsilon_2 \\
\vdots \\
\varepsilon_n
\end{bmatrix}$$`


---
# Estimateur MCO dans le cas multivari√©


L'estimateur des MCO est celui qui minimise la somme des carr√©s des r√©sidus:


$$ \underset{\beta}{min} \;\varepsilon' \varepsilon = (Y - X \beta)' (Y - X \beta) = Y'Y - 2\beta'X'Y + \beta'X'X\beta$$
La condition du premier ordre est: 

$$\frac{\partial(Y'Y - 2\beta'X'Y + \beta'X'X\beta)}{\partial \beta} = -2X'Y + 2X'X\beta =  0 $$
&lt;span style="color:#dd0747"&gt; **Si**&lt;/span&gt; `\(\color{#dd0747}{(X'X)}\)` &lt;span style="color:#dd0747"&gt;**est inversible** (cf H4) &lt;/span&gt;, alors 

$$  (X'X) \beta = X'Y \implies \beta = (X'X)^{-1} X'Y $$


&amp;nbsp;
&lt;button class="inline" onclick="window.location.hash='estimateur'"&gt;Back&lt;/button&gt;




    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
